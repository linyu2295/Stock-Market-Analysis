{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from json.decoder import JSONDecodeError\n",
    "from pandas import json_normalize\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from pandas_datareader import data as pdr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_results(day, top_p, tmp_path, with_sector):\n",
    "    \n",
    "    try:\n",
    "        os.chdir(tmp_path)\n",
    "    except:\n",
    "        print('No such directory found!')\n",
    "\n",
    "    print(tmp_path)\n",
    "\n",
    "    '''\n",
    "        get stock prices and large change stock list\n",
    "    '''\n",
    "    large_change_stocks_all_original = {}\n",
    "    current_prices_original = {}\n",
    "\n",
    "    for p in top_p:\n",
    "        current_path = os.path.join(tmp_path, 'threshold_{}'.format(p))\n",
    "\n",
    "        with open(current_path + '/1_large_change_stocks.json') as f:\n",
    "            large_change_stocks_all_original[p] = json.load(f)\n",
    "\n",
    "        with open(current_path + '/2_current_prices.json') as f:\n",
    "            current_prices_original[p] = json.load(f)\n",
    "\n",
    "    print('iterations: {}'.format(len(current_prices_original[top_p[0]].keys())))\n",
    "\n",
    "    if day < '2020-11-01':\n",
    "        open_time = datetime.datetime(2020, int(day.split('-')[1]), \\\n",
    "                                      int(day.split('-')[2]), 21, 31).isoformat()\n",
    "    else:\n",
    "        open_time = datetime.datetime(2020, int(day.split('-')[1]), \\\n",
    "                                  int(day.split('-')[2]), 22, 31).isoformat()\n",
    "\n",
    "    print('Open time: {}'.format(open_time))\n",
    "\n",
    "    large_change_stocks_all = large_change_stocks_all_original.copy()\n",
    "    current_prices = current_prices_original.copy()\n",
    "\n",
    "    if len([k for k, v in large_change_stocks_all_original[top_p[0]].items() if v != []]) == 0:\n",
    "        print('no large change stocks!')\n",
    "\n",
    "    if len(large_change_stocks_all_original[top_p[0]]['1']) != 0 and large_change_stocks_all_original[top_p[0]]['1'][0][3] < open_time:\n",
    "        large_change_stocks_all[top_p[0]]['1'] = []\n",
    "\n",
    "    '''\n",
    "        sector_etf_prices_all\n",
    "    '''\n",
    "    if with_sector == True:\n",
    "        # read from disk\n",
    "        with open('{}/threshold_{}/4_sector_etf_prices.json'.format(tmp_path, top_p[0]), 'r') as fp:\n",
    "            sector_etf_prices_dict = json.load(fp)\n",
    "\n",
    "        # convert dictionaries into dataframes\n",
    "        sector_etf_prices_all = {\n",
    "            key: pd.DataFrame(sector_etf_prices_dict[key])\n",
    "            for key in sector_etf_prices_dict\n",
    "        }\n",
    "    else:\n",
    "        sector_etf_prices_all = {}\n",
    "\n",
    "    return current_prices, large_change_stocks_all, sector_etf_prices_all\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_large_change_times(current_stock, large_times):\n",
    "    first_large_change = {}\n",
    "    for p in top_p:\n",
    "        first_large_change[p] = {}\n",
    "\n",
    "        n_len = len(large_times[p])\n",
    "        for i in range(n_len):\n",
    "            if current_stock == large_times[p][i][0]:\n",
    "                first_large_change[p][current_stock] = (large_times[p][i][3], large_times[p][i][1], large_times[p][i][2])\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "    return first_large_change\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "   \n",
    "   Get opening price as the first data point\n",
    "        \n",
    "'''\n",
    "from pandas_datareader import data as pdr\n",
    "\n",
    "def get_stock_openprice(unique_stocks, day):\n",
    "    \n",
    "    large_stock_openprice = {}\n",
    "    large_stock_hist = {}\n",
    "\n",
    "    for s in sorted(list(unique_stocks)):\n",
    "        tmp_hist = pdr.get_data_yahoo(s, start = day, end = day)\n",
    "        large_stock_hist[s] = tmp_hist\n",
    "        tmp_hist = tmp_hist[~tmp_hist.index.duplicated(keep='first')]\n",
    "\n",
    "        large_stock_openprice[s] = tmp_hist.loc[day]\n",
    "\n",
    "    return large_stock_openprice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stock_prices(day, top_p, df_thre_at_q, relative_thre_at_q_lists, \n",
    "                     current_prices, large_change_stocks_all, \n",
    "                     sector_etf_prices_all,\n",
    "                     pic_path, with_sector):\n",
    "\n",
    "    if len([k for k, v in large_change_stocks_all[top_p[0]].items() if v != []]) == 0:\n",
    "        print('No large change stock found!')\n",
    "    else:\n",
    "\n",
    "        '''\n",
    "           stocks_list: \n",
    "           n_stocks: number of stocks\n",
    "        '''\n",
    "\n",
    "        stocks_list = [x[0] for x in current_prices[top_p[0]]['2']]\n",
    "        n_stocks = len(stocks_list)\n",
    "\n",
    "        print('Number of stocks in the list:', n_stocks)\n",
    "\n",
    "\n",
    "        '''\n",
    "            Get individual stock prices\n",
    "                - individual_stock_price: \n",
    "                    - key: stock symbol\n",
    "                    - value: key - timestamp, value - stock price\n",
    "        '''\n",
    "        individual_stock_price = {}\n",
    "        for s in stocks_list:\n",
    "        #     print(s)\n",
    "            individual_stock_price[s] = {}\n",
    "\n",
    "            for p in top_p:\n",
    "                n_cnts = len(current_prices[p].keys())\n",
    "\n",
    "                for k, v in current_prices[p].items():\n",
    "                    for i in v:\n",
    "                        if i[0] == s:\n",
    "                            individual_stock_price[s][datetime.datetime.strptime(i[1], \"%Y-%m-%dT%H:%M:%S.%f\").isoformat()] = \\\n",
    "                                float(str(i[2]).replace(',',''))\n",
    "\n",
    "\n",
    "        '''\n",
    "            large_times:\n",
    "                key: 95th\n",
    "                value: (symbol, price, %change, time)\n",
    "            large_stocks:\n",
    "                key: 95th\n",
    "                value: set of large change stocks\n",
    "        '''\n",
    "        large_times = {}\n",
    "        large_stocks = {}\n",
    "\n",
    "        for p in top_p:\n",
    "\n",
    "            large_times[p] = []\n",
    "            large_stocks[p] = []\n",
    "\n",
    "            for k, v in large_change_stocks_all[p].items():\n",
    "                if len(v) > 0:\n",
    "                    large_stocks[p].extend([x[0] for x in v])\n",
    "                    large_times[p].extend([(x[0], float(x[1].replace(',', '')), x[2], datetime.datetime.strptime(x[3], \"%Y-%m-%dT%H:%M:%S.%f\").isoformat()) for x in v])\n",
    "\n",
    "            large_stocks[p] = set(large_stocks[p])\n",
    "\n",
    "        print(large_stocks[top_p[0]], large_times[top_p[0]][0])\n",
    "\n",
    "\n",
    "        '''\n",
    "            first_large_change: \n",
    "                key: symbol\n",
    "                value: dict of \n",
    "                    key: 95th\n",
    "                    value: k=symbol, v=(time, price, %change)\n",
    "        '''\n",
    "\n",
    "        first_large_change = {}\n",
    "\n",
    "        unique_stocks = set()\n",
    "        for k,v in large_stocks.items():\n",
    "            unique_stocks = unique_stocks.union(v)\n",
    "\n",
    "        for s in sorted(list(unique_stocks)):\n",
    "            first_large_change[s] = get_first_large_change_times(s, large_times)\n",
    "\n",
    "        print(first_large_change)\n",
    "\n",
    "\n",
    "        '''\n",
    "            large_stock_price:\n",
    "                key: symbol\n",
    "                value: df-stock price for each iteration, index=time, value=price\n",
    "        '''\n",
    "        large_stock_price = {}\n",
    "        for k, v in individual_stock_price.items():\n",
    "            if k in unique_stocks:\n",
    "                large_stock_price[k] = v\n",
    "\n",
    "\n",
    "        for k, v in large_stock_price.items():\n",
    "            large_stock_price[k] = pd.DataFrame(v.values(), index=v.keys(), columns=[k])\n",
    "            large_stock_price[k].sort_index(inplace=True)\n",
    "\n",
    "#         print(large_stock_price.keys())\n",
    "\n",
    "        \n",
    "        '''\n",
    "            sector_stock_price:\n",
    "                key: symbol\n",
    "                value: df-stock price for each iteration, index=time, value=price\n",
    "\n",
    "        '''\n",
    "        if with_sector == True:\n",
    "            sector_stock_price = {}\n",
    "\n",
    "            for s in sector_list:\n",
    "                sector_stock_price[s] = {}\n",
    "                for k, v in sector_etf_prices_all.items():\n",
    "                    tmp_datetime = v[v['Symbol'] == s].iloc[0, 1]\n",
    "                    tmp_price = v[v['Symbol'] == s].iloc[0, 2]\n",
    "                    sector_stock_price[s][tmp_datetime] = float(str(tmp_price).replace(',',''))\n",
    "\n",
    "            for k, v in sector_stock_price.items():\n",
    "                sector_stock_price[k] = pd.DataFrame(v.values(), index=v.keys(), columns=[k])\n",
    "                sector_stock_price[k].sort_index(inplace=True)\n",
    "\n",
    "#             print(sector_stock_price.keys())\n",
    "\n",
    "        '''\n",
    "            Stock price change plot:\n",
    "                - red dot: first detect large price change\n",
    "        '''\n",
    "\n",
    "        large_stock_price_copy = large_stock_price.copy()\n",
    "\n",
    "\n",
    "        if day < '2020-11-01':\n",
    "            open_time = datetime.datetime(2020, int(day.split('-')[1]), int(day.split('-')[2]), 21, 31).isoformat()\n",
    "        else:\n",
    "            open_time = datetime.datetime(2020, int(day.split('-')[1]), int(day.split('-')[2]), 22, 31).isoformat()\n",
    "\n",
    "        n_col = ['ro', 'bo', 'yo']\n",
    "\n",
    "\n",
    "        if not os.path.exists(pic_path):\n",
    "            os.mkdir(pic_path)\n",
    "\n",
    "        with PdfPages('{}/all_stocks_price_plot_{}.pdf'.format(pic_path, day)) as pdf:\n",
    "            for s in sorted(list(unique_stocks)):\n",
    "                p_time = []\n",
    "                for p in top_p:\n",
    "                    if first_large_change[s][p]:\n",
    "                        p_time.append((p, first_large_change[s][p][s]))\n",
    "                print(s, p_time)\n",
    "\n",
    "                if large_stock_price[s].index[0] > open_time:\n",
    "                    ####\n",
    "                    large_stock_openprice = get_stock_openprice(unique_stocks, day)\n",
    "\n",
    "                    # adding open price in the stock price list \n",
    "                    large_stock_price_copy[s] = pd.concat([pd.DataFrame({s: large_stock_openprice[s].loc['Open']}, index=[open_time]), \\\n",
    "                              large_stock_price_copy[s]])\n",
    "\n",
    "                large_stock_price_copy[s] = large_stock_price_copy[s].sort_index()\n",
    "                \n",
    "                # get length of stock prices\n",
    "                p_len = len(large_stock_price_copy[s].index)\n",
    "\n",
    "                insert_index = [(p_time[i][0], sum(p_time[i][1][0] > large_stock_price_copy[s].index)) for i in range(len(p_time))]\n",
    "                print(insert_index)\n",
    "\n",
    "                s_change = [(large_stock_price_copy[s].iloc[i, 0] - \\\n",
    "                            large_stock_price_copy[s].iloc[0, 0])/large_stock_price_copy[s].iloc[0, 0]*100 for i in range(large_stock_price_copy[s].shape[0])]\n",
    "\n",
    "                if with_sector == True:\n",
    "                    tmp_sector = stocks_combine_list_with_sector[stocks_combine_list_with_sector['Symbol'] == s]['Sector_ETF'].values[0]\n",
    "                    print(tmp_sector)\n",
    "\n",
    "                    # relative % change: \n",
    "                    sector_change = [(sector_stock_price[tmp_sector].iloc[i, 0] - \\\n",
    "                                     sector_stock_price[tmp_sector].iloc[0, 0])/sector_stock_price[tmp_sector].iloc[0, 0]*100 for i in range(sector_stock_price[tmp_sector].shape[0])]\n",
    "\n",
    "                    relative_change = [round((s_change[i] - sector_c)/sector_c, 1) for i, sector_c in enumerate(sector_change)]\n",
    "\n",
    "\n",
    "                if insert_index[0][1] > 1:\n",
    "                    \n",
    "                    if with_sector == True:\n",
    "                        fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(15,5))\n",
    "\n",
    "                        # subplot: 1\n",
    "                        ax1.plot(range(p_len), large_stock_price_copy[s].values, 'o-')\n",
    "\n",
    "                        dot = {}\n",
    "                        for i in range(len(p_time)):\n",
    "                            dot[i], = ax1.plot(insert_index[i][1]-1, p_time[i][1][1], n_col[i])\n",
    "\n",
    "                        ax1.legend(list(dot.values()), ['Relative diff against {}: {}%'.format(tmp_sector, round(p_time[i][1][2], 2)) for p in p_time], loc = 4)\n",
    "                        ax1.set_xlabel('Iteration')\n",
    "                        ax1.set_ylabel('Price')\n",
    "                        ax1.set_title('{}: {} ({})'.format(day, stocks_combine_list_with_sector[stocks_combine_list_with_sector['Symbol'] == s].iloc[0]['Name'], s))\n",
    "                        txt = \"Stock {}: {} relative difference (2.5th and 97.5th: {}) and 95th-threshold: {}% \\n at time {} with price ${}\".format(s, \n",
    "                                             round(p_time[0][1][2], 2), [round(x, 2) for x in relative_thre_at_q_lists[stocks_combine_list_with_sector[stocks_combine_list_with_sector['Symbol'] == s].index[0]]],\n",
    "                                             round(df_thre_at_q[df_thre_at_q['symbols']==s]['threshold_at_{}'.format(top_p[0])].values[0], 2),\n",
    "                                             p_time[0][1][0], p_time[0][1][1])\n",
    "                        ax1.text(0.05, 0.95, txt, transform=fig.transFigure, size = 8)\n",
    "                        \n",
    "                        for i, txt in enumerate(s_change):\n",
    "                            ax1.annotate('{}%'.format(round(txt,1)), (i+0.4, large_stock_price_copy[s].values[i]))\n",
    "\n",
    "\n",
    "                        # subplot: 2\n",
    "                        ax2.plot(range(len(sector_stock_price[tmp_sector].index)), \n",
    "                             sector_stock_price[tmp_sector].values, 'o-', label = tmp_sector)\n",
    "\n",
    "                        dot = {}\n",
    "                        for i in range(len(p_time)):\n",
    "                            dot[i], = ax2.plot(insert_index[i][1]-1, sector_stock_price[tmp_sector].iloc[insert_index[i][1]-1, 0], \n",
    "                                               n_col[i], label = 'large_change')\n",
    "\n",
    "\n",
    "                        for i, txt in enumerate(relative_change):\n",
    "                            ax2.annotate(txt, (i+0.4, sector_stock_price[tmp_sector].values[i]))\n",
    "\n",
    "\n",
    "                        ax2.set_xlabel('Iteration')\n",
    "                        ax2.set_ylabel('Price')\n",
    "                        ax2.legend()\n",
    "                        ax2.set_title('{}: {} ({})'.format(day, stocks_combine_list_with_sector[stocks_combine_list_with_sector['Sector_ETF'] == tmp_sector].iloc[0]['Sector'], tmp_sector))\n",
    "\n",
    "                        pdf.savefig(fig)\n",
    "                        plt.close()\n",
    "                    else:\n",
    "\n",
    "                        fig = plt.figure(figsize=(7, 5))\n",
    "                        plt.plot(range(p_len), large_stock_price_copy[s].values, 'o-')\n",
    "\n",
    "                        dot = {}\n",
    "                        for i in range(len(p_time)):\n",
    "                            dot[i], = plt.plot(insert_index[i][1]-1, p_time[i][1][1], n_col[i])\n",
    "\n",
    "                        plt.legend(list(dot.values()), ['Percentage Change: {}%'.format(p_time[i][1][2]) for p in p_time], loc = 4)\n",
    "                        plt.xlabel('Iteration')\n",
    "                        plt.ylabel('Price')\n",
    "                        plt.title('{}: {} ({})'.format(day, stocks_combine_list_with_sector[stocks_combine_list_with_sector['Symbol'] == s].iloc[0]['Name'], s))\n",
    "                        txt = \"Stock {}: {}% change (threshold {}%) \\n at time {} with price ${}\".format(s, \n",
    "                                             p_time[0][1][2], round(df_thre_at_q[df_thre_at_q['symbols']==s]['threshold_at_{}'.format(top_p[0])].values[0], 2), \n",
    "                                             p_time[0][1][0], p_time[0][1][1])\n",
    "                        plt.text(0.05, 0.95, txt, transform=fig.transFigure, size = 8)\n",
    "\n",
    "                        for i, txt in enumerate(s_change):\n",
    "                            plt.annotate('{}%'.format(round(txt,1)), (i+0.4, large_stock_price_copy[s].values[i]))\n",
    "\n",
    "                        pdf.savefig(fig)\n",
    "                        plt.close()\n",
    "\n",
    "\n",
    "    \n",
    "        return unique_stocks, first_large_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2020-10-02', '2020-10-05', '2020-10-06', '2020-10-07', '2020-10-13', '2020-10-14', '2020-10-15', '2020-10-16', '2020-10-19', '2020-10-20', '2020-10-21', '2020-10-22', '2020-10-23', '2020-10-26', '2020-10-27', '2020-10-28', '2020-10-29', '2020-10-30', '2020-11-03', '2020-11-04', '2020-11-05', '2020-11-06', '2020-11-09', '2020-11-10']\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    dates_filename_list: \n",
    "    top_p: \n",
    "        95th percentile as the threshold to detect a stock with large change\n",
    "    sub_industry: \n",
    "        focus on mid-cap and large-cap companies\n",
    "\n",
    "'''\n",
    "parent_dir = '/Users/lin/Downloads/Q3_Web_scraping/'\n",
    "\n",
    "sub_industry = 'mid_large_cap_stocks'\n",
    "\n",
    "top_p = [95]\n",
    "\n",
    "dates_filename_list = sorted([filename for filename in os.listdir('{}mid_large_cap_stocks/'.format(parent_dir)) \n",
    "                              if filename.startswith('2020')])\n",
    "print(dates_filename_list)\n",
    "\n",
    "\n",
    "df_thre_at_q = pd.read_csv('{}df_thre_at_q{}.csv'.format(parent_dir,\\\n",
    "                                                               top_p[0]), index_col=0)\n",
    "\n",
    "# load\n",
    "with open(\"{}/relative_thre_at_q_lists.json\".format(os.path.join(parent_dir, 'mid_large_cap_stocks'))) as f:\n",
    "    relative_thre_at_q_lists = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['XLB', 'XLC', 'XLE', 'XLF', 'XLI', 'XLK', 'XLP', 'XLRE', 'XLU', 'XLV', 'XLY']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Size</th>\n",
       "      <th>Market_Cap</th>\n",
       "      <th>Name</th>\n",
       "      <th>Security_Type</th>\n",
       "      <th>Security_Price</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Sub_Industry</th>\n",
       "      <th>Exchange</th>\n",
       "      <th>Headquarters_Location</th>\n",
       "      <th>Sector_ETF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>large-cap</td>\n",
       "      <td>1.876243e+12</td>\n",
       "      <td>Apple Inc</td>\n",
       "      <td>Common Stock</td>\n",
       "      <td>315.01</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Technology Hardware, Storage &amp; Peripherals</td>\n",
       "      <td>Technology Hardware, Storage &amp; Peripherals</td>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>XLK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AB</td>\n",
       "      <td>mid-cap</td>\n",
       "      <td>2.589199e+09</td>\n",
       "      <td>AllianceBernstein Holding LP</td>\n",
       "      <td>Unit Trust Fund</td>\n",
       "      <td>22.51</td>\n",
       "      <td>Financials</td>\n",
       "      <td>Capital Markets</td>\n",
       "      <td>Asset Management &amp; Custody Banks</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>XLF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABT</td>\n",
       "      <td>large-cap</td>\n",
       "      <td>1.786819e+11</td>\n",
       "      <td>Abbott Laboratories</td>\n",
       "      <td>Common Stock</td>\n",
       "      <td>96.07</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care Equipment &amp; Supplies</td>\n",
       "      <td>Health Care Equipment</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>XLV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACC</td>\n",
       "      <td>mid-cap</td>\n",
       "      <td>4.614801e+09</td>\n",
       "      <td>American Campus Communities Inc</td>\n",
       "      <td>Common Stock (REIT)</td>\n",
       "      <td>30.59</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>Equity Real Estate Investment Trusts (REITs)</td>\n",
       "      <td>Residential REITs</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>XLRE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADBE</td>\n",
       "      <td>large-cap</td>\n",
       "      <td>2.243249e+11</td>\n",
       "      <td>Adobe Inc</td>\n",
       "      <td>Common Stock</td>\n",
       "      <td>371.42</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Software</td>\n",
       "      <td>Application Software</td>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>XLK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Symbol       Size    Market_Cap                             Name  \\\n",
       "0   AAPL  large-cap  1.876243e+12                        Apple Inc   \n",
       "1     AB    mid-cap  2.589199e+09     AllianceBernstein Holding LP   \n",
       "2    ABT  large-cap  1.786819e+11              Abbott Laboratories   \n",
       "3    ACC    mid-cap  4.614801e+09  American Campus Communities Inc   \n",
       "4   ADBE  large-cap  2.243249e+11                        Adobe Inc   \n",
       "\n",
       "         Security_Type  Security_Price                  Sector  \\\n",
       "0         Common Stock          315.01  Information Technology   \n",
       "1      Unit Trust Fund           22.51              Financials   \n",
       "2         Common Stock           96.07             Health Care   \n",
       "3  Common Stock (REIT)           30.59             Real Estate   \n",
       "4         Common Stock          371.42  Information Technology   \n",
       "\n",
       "                                       Industry  \\\n",
       "0    Technology Hardware, Storage & Peripherals   \n",
       "1                               Capital Markets   \n",
       "2              Health Care Equipment & Supplies   \n",
       "3  Equity Real Estate Investment Trusts (REITs)   \n",
       "4                                      Software   \n",
       "\n",
       "                                 Sub_Industry Exchange  \\\n",
       "0  Technology Hardware, Storage & Peripherals   NASDAQ   \n",
       "1            Asset Management & Custody Banks     NYSE   \n",
       "2                       Health Care Equipment     NYSE   \n",
       "3                           Residential REITs     NYSE   \n",
       "4                        Application Software   NASDAQ   \n",
       "\n",
       "      Headquarters_Location Sector_ETF  \n",
       "0  United States of America        XLK  \n",
       "1  United States of America        XLF  \n",
       "2  United States of America        XLV  \n",
       "3  United States of America       XLRE  \n",
       "4  United States of America        XLK  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks_combine_list_with_sector = pd.read_csv('{}/{}/stocks_combine_list_with_sector.csv'.format(parent_dir, sub_industry), \n",
    "                                             index_col=0)\n",
    "sector_list = sorted(list(stocks_combine_list_with_sector['Sector_ETF'].unique()))\n",
    "print(sector_list)\n",
    "\n",
    "stocks_combine_list_with_sector.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2020-11-10']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates_filename_list[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-10\n",
      "/Users/lin/Downloads/Q3_Web_scraping/mid_large_cap_stocks/2020-11-10\n",
      "iterations: 26\n",
      "Open time: 2020-11-10T22:31:00\n",
      "Number of stocks in the list: 167\n",
      "{'IDXX', 'QDEL', 'TRUP', 'SLM', 'MCD', 'ORLY', 'ALLY', 'CCI', 'FVRR', 'HIW', 'WELL', 'IBKC', 'UA', 'EQR', 'EPR', 'PPD', 'ACC', 'TWST', 'WAT', 'RL', 'TM', 'CHDN', 'PHM', 'ISRG', 'TPH', 'MS', 'CMA', 'HTHT', 'MPW', 'REGN', 'PINS', 'LLY', 'STAY', 'ALL', 'CPB', 'JNJ', 'FLO', 'TROW', 'UMPQ', 'AMT', 'PLD', 'KMX', 'QGEN', 'PRU', 'HBAN', 'SF', 'ARE', 'SPOT', 'TFX', 'CR', 'NVCR', 'BYD', 'AXS', 'CVS', 'SRPT', 'AMED', 'BNS', 'HSBC', 'ALGN', 'O', 'F', 'TWTR', 'ADC', 'AMP', 'AB', 'DRE', 'HOMB', 'WBK'} ('AMP', 180.97, 14.428571428571427, '2020-11-10T22:39:35.972646')\n",
      "{'AB': {95: {'AB': ('2020-11-11T01:38:29.064829', 31.78, 12.727272727272727)}}, 'ACC': {95: {'ACC': ('2020-11-10T22:55:39.186822', 40.76, 15.818181818181818)}}, 'ADC': {95: {'ADC': ('2020-11-10T22:55:39.186822', 64.98, 20.454545454545453)}}, 'ALGN': {95: {'ALGN': ('2020-11-10T23:10:46.753503', 466.78, 213.00000000000003)}}, 'ALL': {95: {'ALL': ('2020-11-11T00:23:50.066322', 93.48, 13.666666666666668)}}, 'ALLY': {95: {'ALLY': ('2020-11-11T00:23:50.066322', 29.65, 23.666666666666668)}}, 'AMED': {95: {'AMED': ('2020-11-10T23:10:46.753503', 239.85, 215.00000000000003)}}, 'AMP': {95: {'AMP': ('2020-11-10T22:39:35.972646', 180.97, 14.428571428571427)}}, 'AMT': {95: {'AMT': ('2020-11-11T02:38:37.305746', 231.77, 260.0)}}, 'ARE': {95: {'ARE': ('2020-11-11T00:53:33.355659', 158.51, 16.999999999999996)}}, 'AXS': {95: {'AXS': ('2020-11-11T01:38:29.064829', 48.95, 11.772727272727272)}}, 'BNS': {95: {'BNS': ('2020-11-11T01:38:29.064829', 47.0, 9.409090909090908)}}, 'BYD': {95: {'BYD': ('2020-11-11T01:23:31.307754', 34.76, 196.0)}}, 'CCI': {95: {'CCI': ('2020-11-11T02:38:37.305746', 158.38, 209.00000000000003)}}, 'CHDN': {95: {'CHDN': ('2020-11-11T01:23:31.307754', 186.78, 357.0)}}, 'CMA': {95: {'CMA': ('2020-11-11T01:08:31.531067', 53.14, 35.5)}}, 'CPB': {95: {'CPB': ('2020-11-10T22:39:35.972646', 45.82, 31.5)}}, 'CR': {95: {'CR': ('2020-11-10T22:39:35.972646', 60.3, 34.35)}}, 'CVS': {95: {'CVS': ('2020-11-10T23:28:59.564713', 70.07, 25.85714285714285)}}, 'DRE': {95: {'DRE': ('2020-11-10T22:55:39.186822', 38.95, 5.818181818181818)}}, 'EPR': {95: {'EPR': ('2020-11-11T02:38:37.305746', 32.21, 266.0)}}, 'EQR': {95: {'EQR': ('2020-11-10T22:55:39.186822', 61.79, 37.45454545454545)}}, 'F': {95: {'F': ('2020-11-11T01:23:31.307754', 8.58, 462.0)}}, 'FLO': {95: {'FLO': ('2020-11-10T22:39:35.972646', 22.22, 37.0)}}, 'FVRR': {95: {'FVRR': ('2020-11-11T00:53:33.355659', 141.82, 45.76470588235294)}}, 'HBAN': {95: {'HBAN': ('2020-11-10T22:39:35.972646', 11.82, 15.0)}}, 'HIW': {95: {'HIW': ('2020-11-11T00:53:33.355659', 34.84, 21.875)}}, 'HOMB': {95: {'HOMB': ('2020-11-10T23:28:59.564713', 19.33, 12.242424242424242)}}, 'HSBC': {95: {'HSBC': ('2020-11-10T22:39:35.972646', 24.48, 5.7142857142857135)}}, 'HTHT': {95: {'HTHT': ('2020-11-11T01:23:31.307754', 45.13, 35.0)}}, 'IBKC': {95: {'IBKC': ('2020-11-10T22:39:35.972646', 43.08, 76.14285714285714)}}, 'IDXX': {95: {'IDXX': ('2020-11-10T23:10:46.753503', 429.05, 169.0)}}, 'ISRG': {95: {'ISRG': ('2020-11-10T23:10:46.753503', 747.64, 333.0)}}, 'JNJ': {95: {'JNJ': ('2020-11-11T02:23:48.498959', 147.55, 8.181818181818182)}}, 'KMX': {95: {'KMX': ('2020-11-11T02:08:05.781904', 96.37, 41.0)}}, 'LLY': {95: {'LLY': ('2020-11-10T22:55:39.186822', 146.15, 43.833333333333336)}}, 'MCD': {95: {'MCD': ('2020-11-11T01:23:31.307754', 213.58, 16.0)}}, 'MPW': {95: {'MPW': ('2020-11-11T04:23:36.688439', 19.43, 16.857142857142854)}}, 'MS': {95: {'MS': ('2020-11-10T23:40:49.846695', 54.96, 22.624999999999996)}}, 'NVCR': {95: {'NVCR': ('2020-11-10T23:10:46.753503', 121.78, 313.0)}}, 'O': {95: {'O': ('2020-11-10T22:55:39.186822', 63.01, 19.81818181818182)}}, 'ORLY': {95: {'ORLY': ('2020-11-11T01:23:31.307754', 465.43, 227.0)}}, 'PHM': {95: {'PHM': ('2020-11-11T01:23:31.307754', 41.67, 252.0)}}, 'PINS': {95: {'PINS': ('2020-11-11T04:38:35.415107', 55.45, 55.857142857142854)}}, 'PLD': {95: {'PLD': ('2020-11-11T02:38:37.305746', 98.26, 135.0)}}, 'PPD': {95: {'PPD': ('2020-11-11T00:38:34.903071', 33.7, 96.0)}}, 'PRU': {95: {'PRU': ('2020-11-11T01:53:14.309813', 75.33, 12.473684210526317)}}, 'QDEL': {95: {'QDEL': ('2020-11-11T00:38:34.903071', 199.04, 226.00000000000003)}}, 'QGEN': {95: {'QGEN': ('2020-11-10T23:10:46.753503', 45.6, 399.0)}}, 'REGN': {95: {'REGN': ('2020-11-10T23:10:46.753503', 550.99, 291.0)}}, 'RL': {95: {'RL': ('2020-11-11T01:23:31.307754', 82.07, 39.0)}}, 'SF': {95: {'SF': ('2020-11-11T02:53:02.713637', 69.78, 18.46153846153846)}}, 'SLM': {95: {'SLM': ('2020-11-11T02:53:02.713637', 10.68, 15.538461538461538)}}, 'SPOT': {95: {'SPOT': ('2020-11-11T01:23:31.307754', 260.09, 21.391304347826086)}}, 'SRPT': {95: {'SRPT': ('2020-11-10T23:10:46.753503', 123.26, 182.0)}}, 'STAY': {95: {'STAY': ('2020-11-11T00:53:33.355659', 13.1, 21.058823529411764)}}, 'TFX': {95: {'TFX': ('2020-11-10T23:10:46.753503', 355.64, 228.00000000000003)}}, 'TM': {95: {'TM': ('2020-11-11T01:23:31.307754', 141.43, 127.0)}}, 'TPH': {95: {'TPH': ('2020-11-11T01:23:31.307754', 17.08, 568.0)}}, 'TROW': {95: {'TROW': ('2020-11-10T23:10:46.753503', 135.25, 10.818181818181818)}}, 'TRUP': {95: {'TRUP': ('2020-11-10T23:10:46.753503', 80.62, 47.63636363636363)}}, 'TWST': {95: {'TWST': ('2020-11-10T23:10:46.753503', 94.11, 168.0)}}, 'TWTR': {95: {'TWTR': ('2020-11-11T04:38:35.415107', 42.26, 29.71428571428571)}}, 'UA': {95: {'UA': ('2020-11-11T01:23:31.307754', 13.66, 106.0)}}, 'UMPQ': {95: {'UMPQ': ('2020-11-11T01:53:14.309813', 14.32, 16.05263157894737)}}, 'WAT': {95: {'WAT': ('2020-11-10T23:10:46.753503', 227.12, 143.0)}}, 'WBK': {95: {'WBK': ('2020-11-10T22:39:35.972646', 13.65, 10.428571428571427)}}, 'WELL': {95: {'WELL': ('2020-11-10T22:55:39.186822', 68.38, 22.454545454545457)}}}\n",
      "AB [(95, ('2020-11-11T01:38:29.064829', 31.78, 12.727272727272727))]\n",
      "[(95, 14)]\n",
      "XLF\n",
      "ACC [(95, ('2020-11-10T22:55:39.186822', 40.76, 15.818181818181818))]\n",
      "[(95, 3)]\n",
      "XLRE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADC [(95, ('2020-11-10T22:55:39.186822', 64.98, 20.454545454545453))]\n",
      "[(95, 3)]\n",
      "XLRE\n",
      "ALGN [(95, ('2020-11-10T23:10:46.753503', 466.78, 213.00000000000003))]\n",
      "[(95, 4)]\n",
      "XLV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL [(95, ('2020-11-11T00:23:50.066322', 93.48, 13.666666666666668))]\n",
      "[(95, 9)]\n",
      "XLF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALLY [(95, ('2020-11-11T00:23:50.066322', 29.65, 23.666666666666668))]\n",
      "[(95, 9)]\n",
      "XLF\n",
      "AMED [(95, ('2020-11-10T23:10:46.753503', 239.85, 215.00000000000003))]\n",
      "[(95, 4)]\n",
      "XLV\n",
      "AMP [(95, ('2020-11-10T22:39:35.972646', 180.97, 14.428571428571427))]\n",
      "[(95, 2)]\n",
      "XLF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMT [(95, ('2020-11-11T02:38:37.305746', 231.77, 260.0))]\n",
      "[(95, 18)]\n",
      "XLRE\n",
      "ARE [(95, ('2020-11-11T00:53:33.355659', 158.51, 16.999999999999996))]\n",
      "[(95, 11)]\n",
      "XLRE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AXS [(95, ('2020-11-11T01:38:29.064829', 48.95, 11.772727272727272))]\n",
      "[(95, 14)]\n",
      "XLF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BNS [(95, ('2020-11-11T01:38:29.064829', 47.0, 9.409090909090908))]\n",
      "[(95, 14)]\n",
      "XLF\n",
      "BYD [(95, ('2020-11-11T01:23:31.307754', 34.76, 196.0))]\n",
      "[(95, 13)]\n",
      "XLY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCI [(95, ('2020-11-11T02:38:37.305746', 158.38, 209.00000000000003))]\n",
      "[(95, 18)]\n",
      "XLRE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHDN [(95, ('2020-11-11T01:23:31.307754', 186.78, 357.0))]\n",
      "[(95, 13)]\n",
      "XLY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMA [(95, ('2020-11-11T01:08:31.531067', 53.14, 35.5))]\n",
      "[(95, 12)]\n",
      "XLF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPB [(95, ('2020-11-10T22:39:35.972646', 45.82, 31.5))]\n",
      "[(95, 2)]\n",
      "XLP\n",
      "CR [(95, ('2020-11-10T22:39:35.972646', 60.3, 34.35))]\n",
      "[(95, 2)]\n",
      "XLI"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CVS [(95, ('2020-11-10T23:28:59.564713', 70.07, 25.85714285714285))]\n",
      "[(95, 5)]\n",
      "XLV\n",
      "DRE [(95, ('2020-11-10T22:55:39.186822', 38.95, 5.818181818181818))]\n",
      "[(95, 3)]\n",
      "XLRE"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPR [(95, ('2020-11-11T02:38:37.305746', 32.21, 266.0))]\n",
      "[(95, 18)]\n",
      "XLRE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EQR [(95, ('2020-11-10T22:55:39.186822', 61.79, 37.45454545454545))]\n",
      "[(95, 3)]\n",
      "XLRE\n",
      "F [(95, ('2020-11-11T01:23:31.307754', 8.58, 462.0))]\n",
      "[(95, 13)]\n",
      "XLY\n",
      "FLO [(95, ('2020-11-10T22:39:35.972646', 22.22, 37.0))]\n",
      "[(95, 2)]\n",
      "XLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FVRR [(95, ('2020-11-11T00:53:33.355659', 141.82, 45.76470588235294))]\n",
      "[(95, 11)]\n",
      "XLY\n",
      "HBAN [(95, ('2020-11-10T22:39:35.972646', 11.82, 15.0))]\n",
      "[(95, 2)]\n",
      "XLF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIW [(95, ('2020-11-11T00:53:33.355659', 34.84, 21.875))]\n",
      "[(95, 11)]\n",
      "XLRE\n",
      "HOMB [(95, ('2020-11-10T23:28:59.564713', 19.33, 12.242424242424242))]\n",
      "[(95, 5)]\n",
      "XLF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HSBC [(95, ('2020-11-10T22:39:35.972646', 24.48, 5.7142857142857135))]\n",
      "[(95, 2)]\n",
      "XLF\n",
      "HTHT [(95, ('2020-11-11T01:23:31.307754', 45.13, 35.0))]\n",
      "[(95, 13)]\n",
      "XLY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IBKC [(95, ('2020-11-10T22:39:35.972646', 43.08, 76.14285714285714))]\n",
      "[(95, 2)]\n",
      "XLF\n",
      "IDXX [(95, ('2020-11-10T23:10:46.753503', 429.05, 169.0))]\n",
      "[(95, 4)]\n",
      "XLV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISRG [(95, ('2020-11-10T23:10:46.753503', 747.64, 333.0))]\n",
      "[(95, 4)]\n",
      "XLV\n",
      "JNJ [(95, ('2020-11-11T02:23:48.498959', 147.55, 8.181818181818182))]\n",
      "[(95, 17)]\n",
      "XLV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMX [(95, ('2020-11-11T02:08:05.781904', 96.37, 41.0))]\n",
      "[(95, 16)]\n",
      "XLY\n",
      "LLY [(95, ('2020-11-10T22:55:39.186822', 146.15, 43.833333333333336))]\n",
      "[(95, 3)]\n",
      "XLV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCD [(95, ('2020-11-11T01:23:31.307754', 213.58, 16.0))]\n",
      "[(95, 13)]\n",
      "XLY\n",
      "MPW [(95, ('2020-11-11T04:23:36.688439', 19.43, 16.857142857142854))]\n",
      "[(95, 25)]\n",
      "XLRE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS [(95, ('2020-11-10T23:40:49.846695', 54.96, 22.624999999999996))]\n",
      "[(95, 6)]\n",
      "XLF\n",
      "NVCR [(95, ('2020-11-10T23:10:46.753503', 121.78, 313.0))]\n",
      "[(95, 4)]\n",
      "XLV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O [(95, ('2020-11-10T22:55:39.186822', 63.01, 19.81818181818182))]\n",
      "[(95, 3)]\n",
      "XLRE\n",
      "ORLY [(95, ('2020-11-11T01:23:31.307754', 465.43, 227.0))]\n",
      "[(95, 13)]\n",
      "XLY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHM [(95, ('2020-11-11T01:23:31.307754', 41.67, 252.0))]\n",
      "[(95, 13)]\n",
      "XLY\n",
      "PINS [(95, ('2020-11-11T04:38:35.415107', 55.45, 55.857142857142854))]\n",
      "[(95, 26)]\n",
      "XLC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLD [(95, ('2020-11-11T02:38:37.305746', 98.26, 135.0))]\n",
      "[(95, 18)]\n",
      "XLRE\n",
      "PPD [(95, ('2020-11-11T00:38:34.903071', 33.7, 96.0))]\n",
      "[(95, 10)]\n",
      "XLV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRU [(95, ('2020-11-11T01:53:14.309813', 75.33, 12.473684210526317))]\n",
      "[(95, 15)]\n",
      "XLF\n",
      "QDEL [(95, ('2020-11-11T00:38:34.903071', 199.04, 226.00000000000003))]\n",
      "[(95, 10)]\n",
      "XLV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QGEN [(95, ('2020-11-10T23:10:46.753503', 45.6, 399.0))]\n",
      "[(95, 4)]\n",
      "XLV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REGN [(95, ('2020-11-10T23:10:46.753503', 550.99, 291.0))]\n",
      "[(95, 4)]\n",
      "XLV\n",
      "RL [(95, ('2020-11-11T01:23:31.307754', 82.07, 39.0))]\n",
      "[(95, 13)]\n",
      "XLY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SF [(95, ('2020-11-11T02:53:02.713637', 69.78, 18.46153846153846))]\n",
      "[(95, 19)]\n",
      "XLF\n",
      "SLM [(95, ('2020-11-11T02:53:02.713637', 10.68, 15.538461538461538))]\n",
      "[(95, 19)]\n",
      "XLF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPOT [(95, ('2020-11-11T01:23:31.307754', 260.09, 21.391304347826086))]\n",
      "[(95, 13)]\n",
      "XLC\n",
      "SRPT [(95, ('2020-11-10T23:10:46.753503', 123.26, 182.0))]\n",
      "[(95, 4)]\n",
      "XLV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STAY [(95, ('2020-11-11T00:53:33.355659', 13.1, 21.058823529411764))]\n",
      "[(95, 11)]\n",
      "XLY\n",
      "TFX [(95, ('2020-11-10T23:10:46.753503', 355.64, 228.00000000000003))]\n",
      "[(95, 4)]\n",
      "XLV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TM [(95, ('2020-11-11T01:23:31.307754', 141.43, 127.0))]\n",
      "[(95, 13)]\n",
      "XLY\n",
      "TPH [(95, ('2020-11-11T01:23:31.307754', 17.08, 568.0))]\n",
      "[(95, 13)]\n",
      "XLY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TROW [(95, ('2020-11-10T23:10:46.753503', 135.25, 10.818181818181818))]\n",
      "[(95, 4)]\n",
      "XLF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUP [(95, ('2020-11-10T23:10:46.753503', 80.62, 47.63636363636363))]\n",
      "[(95, 4)]\n",
      "XLF\n",
      "TWST [(95, ('2020-11-10T23:10:46.753503', 94.11, 168.0))]\n",
      "[(95, 4)]\n",
      "XLV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TWTR [(95, ('2020-11-11T04:38:35.415107', 42.26, 29.71428571428571))]\n",
      "[(95, 26)]\n",
      "XLC\n",
      "UA [(95, ('2020-11-11T01:23:31.307754', 13.66, 106.0))]\n",
      "[(95, 13)]\n",
      "XLY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMPQ [(95, ('2020-11-11T01:53:14.309813', 14.32, 16.05263157894737))]\n",
      "[(95, 15)]\n",
      "XLF\n",
      "WAT [(95, ('2020-11-10T23:10:46.753503', 227.12, 143.0))]\n",
      "[(95, 4)]\n",
      "XLV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WBK [(95, ('2020-11-10T22:39:35.972646', 13.65, 10.428571428571427))]\n",
      "[(95, 2)]\n",
      "XLF\n",
      "WELL [(95, ('2020-11-10T22:55:39.186822', 68.38, 22.454545454545457))]\n",
      "[(95, 3)]\n",
      "XLRE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/lin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:182: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "    Stock price movement visualization\n",
    "        1. 2020/10/02 - 2020/11/03: %change compared with 95th percentile threshold obtained from past 1-year data\n",
    "        2. 2020/11/04 - present: get relative difference of the %change between individual stock and corresponding sector ETF\n",
    "                                then, compared the relative difference with the 2.5th and 97.5th percentile thresholds\n",
    "                                obtained from past 1-year data\n",
    "\n",
    "'''\n",
    "\n",
    "# current_prices_d = {}\n",
    "# large_change_stocks_all_d ={}\n",
    "# sector_etf_prices_all_d = {}\n",
    "\n",
    "# unique_stocks_d = {}\n",
    "# first_large_change_d = {}\n",
    "\n",
    "with_sector = False\n",
    "# dates_filename_list\n",
    "\n",
    "for day in dates_filename_list[-1:]:\n",
    "    print(day)\n",
    "\n",
    "    tmp_path = os.path.join(os.path.join(parent_dir, sub_industry),  day)\n",
    "\n",
    "    if day > '2020-11-03':\n",
    "        with_sector = True\n",
    "    else:\n",
    "        with_sector = False\n",
    "        \n",
    "    current_prices_d[day], \\\n",
    "    large_change_stocks_all_d[day], \\\n",
    "    sector_etf_prices_all_d[day] = preprocess_results(day, top_p, tmp_path, with_sector)\n",
    "    \n",
    "    if len([k for k, v in large_change_stocks_all_d[day][top_p[0]].items() if v != []]) == 0:\n",
    "        print('No large change stock found!')\n",
    "        unique_stocks_d[day] = set()\n",
    "        first_large_change_d[day] = dict()\n",
    "    else:\n",
    "        unique_stocks_d[day], \\\n",
    "        first_large_change_d[day] = plot_stock_prices(day, top_p, df_thre_at_q, relative_thre_at_q_lists, \n",
    "                                                     current_prices_d[day], large_change_stocks_all_d[day],\n",
    "                                                     sector_etf_prices_all_d[day], \n",
    "                                                     pic_path=os.path.join(parent_dir, 'stock_price_figures'), \n",
    "                                                     with_sector=with_sector)\n",
    "\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## News and UGC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "   \n",
    "   Get opening price as the first data point\n",
    "        \n",
    "'''\n",
    "\n",
    "\n",
    "def get_large_stock_df(day, unique_stocks_d, first_large_change_d):\n",
    "    \n",
    "\n",
    "    large_stock_openprice = {}\n",
    "    large_stock_hist = {}\n",
    "\n",
    "    for s in sorted(list(unique_stocks_d[day])):\n",
    "        tmp_hist = pdr.get_data_yahoo(s, start = day, end = day)\n",
    "        large_stock_hist[s] = tmp_hist\n",
    "        tmp_hist = tmp_hist[~tmp_hist.index.duplicated(keep='first')]\n",
    "\n",
    "        large_stock_openprice[s] = tmp_hist.loc[day]\n",
    "\n",
    "\n",
    "    large_stock_df = pd.DataFrame(0, index=sorted(list(unique_stocks_d[day])), \n",
    "                                  columns=large_stock_hist[s].columns)\n",
    "    large_stock_df['Thre_at_{}'.format(top_p[0])] = 0\n",
    "    large_stock_df['First_Percent_Change'] = 0\n",
    "    large_stock_df['First_Stock_Price'] = 0\n",
    "\n",
    "    for s in sorted(list(unique_stocks_d[day])):\n",
    "        large_stock_df.loc[s] = large_stock_hist[s].loc[day]\n",
    "        large_stock_df.loc[s, 'Thre_at_{}'.format(top_p[0])] = df_thre_at_q[df_thre_at_q['symbols']==s]['threshold_at_{}'.format(top_p[0])].values\n",
    "        large_stock_df.loc[s, 'First_Percent_Change'] = first_large_change_d[day][s][top_p[0]][s][2]\n",
    "        large_stock_df.loc[s, 'First_Stock_Price'] = first_large_change_d[day][s][top_p[0]][s][1]\n",
    "\n",
    "    large_stock_df = large_stock_df.assign(Total_Percent_Change = lambda x: \n",
    "                                                           round((x['Close'] - x['Open'])/x['Open']*100 ,2))\n",
    "\n",
    "    print(large_stock_df.shape)\n",
    "\n",
    "    large_stock_df.reset_index(inplace=True)\n",
    "    large_stock_df.rename(columns={'index': 'Symbol'}, inplace=True)\n",
    "\n",
    "    large_stock_df = pd.merge(large_stock_df, stocks_midlargeCap_webscrape_df,\n",
    "                        how = 'left', on = 'Symbol')\n",
    "\n",
    "    return large_stock_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Get News and UGC dataframe for each day\n",
    "'''\n",
    "\n",
    "\n",
    "def get_news_ugc_data(day, tmp_path, unique_stocks_d):\n",
    "\n",
    "    res_news_df = {}\n",
    "    res_ugc_df = {}\n",
    "\n",
    "    for s in sorted(list(unique_stocks_d[day])):\n",
    "\n",
    "        news_filename_list = glob.glob(os.path.join(tmp_path, '{}/News_*.json'.format(s)))\n",
    "        ugc_filename_list = glob.glob(os.path.join(tmp_path, '{}/UGC_*.json'.format(s)))\n",
    "\n",
    "        res_news_dict = {}\n",
    "        res_ugc_dict = {}\n",
    "\n",
    "        for news_file in news_filename_list:\n",
    "\n",
    "            with open(news_file) as f:\n",
    "                try:\n",
    "                    res_news_dict[news_file.split('{}/threshold_{}/{}/'.format(day, top_p[0], s))[1]] = json.load(f)\n",
    "                except JSONDecodeError:\n",
    "                    pass\n",
    "            f.close()\n",
    "\n",
    "        res_news_df[s] = pd.DataFrame({'published': [item['published'] for k, v in res_news_dict.items() for item in v],\n",
    "                                    'title':[item['title'] for k, v in res_news_dict.items() for item in v]})\n",
    "        # drop duplicates by title:\n",
    "        res_news_df[s] = res_news_df[s].drop_duplicates('title').reset_index(drop = True)\n",
    "\n",
    "        # drop news that do not contain stock key-words in title:\n",
    "        res_news_df[s] = res_news_df[s][res_news_df[s]['title'].map(lambda x: \\\n",
    "                 any(word in x.lower() for word in stocks_key_words_dict[s]))].reset_index(drop=True)\n",
    "\n",
    "        print('{}: News dataset shape: {}'.format(s, res_news_df[s].shape))\n",
    "\n",
    "        for ugc_file in ugc_filename_list:\n",
    "\n",
    "            with open(ugc_file) as f:\n",
    "                try:\n",
    "                    res_ugc_dict[ugc_file.split('{}/threshold_{}/{}/'.format(day, top_p[0], s))[1]] = json.load(f)\n",
    "                except JSONDecodeError:\n",
    "                    pass\n",
    "            f.close()\n",
    "\n",
    "        res_ugc_df[s] = []\n",
    "        for k, v in res_ugc_dict.items():\n",
    "            tmp_df = pd.DataFrame.from_dict(json_normalize(v['messages']), orient='columns')\n",
    "            res_ugc_df[s].append(tmp_df)\n",
    "\n",
    "        res_ugc_df[s] = pd.concat(res_ugc_df[s])\n",
    "        # drop duplicates by message id:\n",
    "        res_ugc_df[s] = res_ugc_df[s].drop_duplicates('id').reset_index(drop = True)\n",
    "\n",
    "        print('{}: UGC dataset shape: {}'.format(s, res_ugc_df[s].shape))\n",
    "    \n",
    "    return res_news_df, res_ugc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(167, 11)\n"
     ]
    }
   ],
   "source": [
    "stocks_midlargeCap_webscrape_df = pd.read_csv('{}/df_stocks_midlargeCap_webscrape.csv'.format(parent_dir), \n",
    "                                              index_col=0)\n",
    "\n",
    "print(stocks_midlargeCap_webscrape_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-02\n",
      "Found large change stocks: {'HSBC', 'LSCC'}\n",
      "(2, 10)\n",
      "HSBC: News dataset shape: (2, 2)\n",
      "HSBC: UGC dataset shape: (30, 42)\n",
      "LSCC: News dataset shape: (0, 2)\n",
      "LSCC: UGC dataset shape: (30, 34)\n",
      "\n",
      "\n",
      "2020-10-05\n",
      "Found large change stocks: {'EPR', 'LSCC', 'MYOK', 'REGN', 'AGIO', 'AQN', 'ZION', 'ROK', 'PBR', 'WIT', 'MRVL', 'STLD', 'UMC'}\n",
      "(13, 10)\n",
      "AGIO: News dataset shape: (3, 2)\n",
      "AGIO: UGC dataset shape: (30, 40)\n",
      "AQN: News dataset shape: (0, 2)\n",
      "AQN: UGC dataset shape: (30, 40)\n",
      "EPR: News dataset shape: (9, 2)\n",
      "EPR: UGC dataset shape: (61, 41)\n",
      "LSCC: News dataset shape: (0, 2)\n",
      "LSCC: UGC dataset shape: (30, 34)\n",
      "MRVL: News dataset shape: (5, 2)\n",
      "MRVL: UGC dataset shape: (36, 41)\n",
      "MYOK: News dataset shape: (36, 2)\n",
      "MYOK: UGC dataset shape: (114, 42)\n",
      "PBR: News dataset shape: (0, 0)\n",
      "PBR: UGC dataset shape: (30, 43)\n",
      "REGN: News dataset shape: (14, 2)\n",
      "REGN: UGC dataset shape: (428, 43)\n",
      "ROK: News dataset shape: (12, 2)\n",
      "ROK: UGC dataset shape: (32, 34)\n",
      "STLD: News dataset shape: (0, 2)\n",
      "STLD: UGC dataset shape: (30, 40)\n",
      "UMC: News dataset shape: (1, 2)\n",
      "UMC: UGC dataset shape: (36, 42)\n",
      "WIT: News dataset shape: (38, 2)\n",
      "WIT: UGC dataset shape: (38, 40)\n",
      "ZION: News dataset shape: (0, 0)\n",
      "ZION: UGC dataset shape: (30, 36)\n",
      "\n",
      "\n",
      "2020-10-06\n",
      "Found large change stocks: {'WIT', 'CAJ'}\n",
      "(2, 10)\n",
      "CAJ: News dataset shape: (6, 2)\n",
      "CAJ: UGC dataset shape: (30, 36)\n",
      "WIT: News dataset shape: (1, 2)\n",
      "WIT: UGC dataset shape: (30, 40)\n",
      "\n",
      "\n",
      "2020-10-07\n",
      "Found large change stocks: {'HSBC', 'LLY', 'NFLX', 'NVCR', 'SIRI', 'MT', 'QDEL', 'WIT', 'SRPT', 'UMC', 'BMY'}\n",
      "(11, 10)\n",
      "BMY: News dataset shape: (9, 2)\n",
      "BMY: UGC dataset shape: (47, 40)\n",
      "HSBC: News dataset shape: (1, 2)\n",
      "HSBC: UGC dataset shape: (32, 42)\n",
      "LLY: News dataset shape: (9, 2)\n",
      "LLY: UGC dataset shape: (43, 40)\n",
      "MT: News dataset shape: (3, 2)\n",
      "MT: UGC dataset shape: (32, 40)\n",
      "NFLX: News dataset shape: (183, 2)\n",
      "NFLX: UGC dataset shape: (208, 43)\n",
      "NVCR: News dataset shape: (0, 2)\n",
      "NVCR: UGC dataset shape: (51, 43)\n",
      "QDEL: News dataset shape: (2, 2)\n",
      "QDEL: UGC dataset shape: (56, 42)\n",
      "SIRI: News dataset shape: (19, 2)\n",
      "SIRI: UGC dataset shape: (52, 40)\n",
      "SRPT: News dataset shape: (1, 2)\n",
      "SRPT: UGC dataset shape: (33, 42)\n",
      "UMC: News dataset shape: (5, 2)\n",
      "UMC: UGC dataset shape: (40, 43)\n",
      "WIT: News dataset shape: (41, 2)\n",
      "WIT: UGC dataset shape: (32, 40)\n",
      "\n",
      "\n",
      "2020-10-13\n",
      "Found large change stocks: {'HSBC', 'QGEN', 'CAJ', 'EPR', 'LLY', 'F', 'SPOT', 'AB', 'CLX', 'WIT', 'WAT', 'AAPL', 'UMC'}\n",
      "(13, 10)\n",
      "AAPL: News dataset shape: (28, 2)\n",
      "AAPL: UGC dataset shape: (30, 40)\n",
      "AB: News dataset shape: (3, 2)\n",
      "AB: UGC dataset shape: (30, 36)\n",
      "CAJ: News dataset shape: (33, 2)\n",
      "CAJ: UGC dataset shape: (30, 42)\n",
      "CLX: News dataset shape: (0, 2)\n",
      "CLX: UGC dataset shape: (30, 41)\n",
      "EPR: News dataset shape: (1, 2)\n",
      "EPR: UGC dataset shape: (35, 42)\n",
      "F: News dataset shape: (18, 2)\n",
      "F: UGC dataset shape: (30, 42)\n",
      "HSBC: News dataset shape: (0, 2)\n",
      "HSBC: UGC dataset shape: (30, 42)\n",
      "LLY: News dataset shape: (7, 2)\n",
      "LLY: UGC dataset shape: (30, 41)\n",
      "QGEN: News dataset shape: (3, 2)\n",
      "QGEN: UGC dataset shape: (35, 42)\n",
      "SPOT: News dataset shape: (0, 2)\n",
      "SPOT: UGC dataset shape: (33, 43)\n",
      "UMC: News dataset shape: (1, 2)\n",
      "UMC: UGC dataset shape: (30, 40)\n",
      "WAT: News dataset shape: (436, 2)\n",
      "WAT: UGC dataset shape: (38, 40)\n",
      "WIT: News dataset shape: (9, 2)\n",
      "WIT: UGC dataset shape: (30, 40)\n",
      "\n",
      "\n",
      "2020-10-14\n",
      "Found large change stocks: {'PE'}\n",
      "(1, 10)\n",
      "PE: News dataset shape: (31, 2)\n",
      "PE: UGC dataset shape: (31, 40)\n",
      "\n",
      "\n",
      "2020-10-15\n",
      "Found large change stocks: {'TTD', 'TWST', 'HEI'}\n",
      "(3, 10)\n",
      "HEI: News dataset shape: (0, 2)\n",
      "HEI: UGC dataset shape: (30, 36)\n",
      "TTD: News dataset shape: (0, 2)\n",
      "TTD: UGC dataset shape: (104, 43)\n",
      "TWST: News dataset shape: (0, 2)\n",
      "TWST: UGC dataset shape: (33, 43)\n",
      "\n",
      "\n",
      "2020-10-16\n",
      "Found large change stocks: {'JBHT', 'TDC'}\n",
      "(2, 10)\n",
      "JBHT: News dataset shape: (6, 2)\n",
      "JBHT: UGC dataset shape: (52, 42)\n",
      "TDC: News dataset shape: (4, 2)\n",
      "TDC: UGC dataset shape: (32, 34)\n",
      "\n",
      "\n",
      "2020-10-19\n",
      "No large change stock found in day 2020-10-19\n",
      "2020-10-20\n",
      "Found large change stocks: {'MELI', 'CMA'}\n",
      "(2, 10)\n",
      "CMA: News dataset shape: (8, 2)\n",
      "CMA: UGC dataset shape: (35, 39)\n",
      "MELI: News dataset shape: (2, 2)\n",
      "MELI: UGC dataset shape: (50, 43)\n",
      "\n",
      "\n",
      "2020-10-21\n",
      "Found large change stocks: {'AXS', 'CWST', 'NFLX', 'FVRR', 'PINS', 'PE', 'TER', 'COP', 'TWTR', 'TRUP', 'PYPL'}\n",
      "(11, 10)\n",
      "AXS: News dataset shape: (1, 2)\n",
      "AXS: UGC dataset shape: (30, 34)\n",
      "COP: News dataset shape: (17, 2)\n",
      "COP: UGC dataset shape: (31, 40)\n",
      "CWST: News dataset shape: (0, 2)\n",
      "CWST: UGC dataset shape: (33, 36)\n",
      "FVRR: News dataset shape: (1, 2)\n",
      "FVRR: UGC dataset shape: (53, 40)\n",
      "NFLX: News dataset shape: (244, 2)\n",
      "NFLX: UGC dataset shape: (471, 43)\n",
      "PE: News dataset shape: (6, 2)\n",
      "PE: UGC dataset shape: (30, 40)\n",
      "PINS: News dataset shape: (21, 2)\n",
      "PINS: UGC dataset shape: (270, 43)\n",
      "PYPL: News dataset shape: (58, 2)\n",
      "PYPL: UGC dataset shape: (215, 41)\n",
      "TER: News dataset shape: (6, 2)\n",
      "TER: UGC dataset shape: (40, 40)\n",
      "TRUP: News dataset shape: (1, 2)\n",
      "TRUP: UGC dataset shape: (30, 42)\n",
      "TWTR: News dataset shape: (144, 2)\n",
      "TWTR: UGC dataset shape: (183, 43)\n",
      "\n",
      "\n",
      "2020-10-22\n",
      "Found large change stocks: {'AGIO', 'PHM', 'ZION', 'CCI', 'JBLU', 'EFX', 'ALGN', 'UMPQ', 'HBAN', 'TPH', 'PYPL', 'UMC'}\n",
      "(12, 10)\n",
      "AGIO: News dataset shape: (0, 2)\n",
      "AGIO: UGC dataset shape: (36, 40)\n",
      "ALGN: News dataset shape: (24, 2)\n",
      "ALGN: UGC dataset shape: (335, 41)\n",
      "CCI: News dataset shape: (0, 2)\n",
      "CCI: UGC dataset shape: (35, 36)\n",
      "EFX: News dataset shape: (1, 2)\n",
      "EFX: UGC dataset shape: (32, 36)\n",
      "HBAN: News dataset shape: (2, 2)\n",
      "HBAN: UGC dataset shape: (33, 34)\n",
      "JBLU: News dataset shape: (3, 2)\n",
      "JBLU: UGC dataset shape: (41, 38)\n",
      "PHM: News dataset shape: (5, 2)\n",
      "PHM: UGC dataset shape: (32, 38)\n",
      "PYPL: News dataset shape: (9, 2)\n",
      "PYPL: UGC dataset shape: (66, 41)\n",
      "TPH: News dataset shape: (1, 2)\n",
      "TPH: UGC dataset shape: (30, 38)\n",
      "UMC: News dataset shape: (8, 2)\n",
      "UMC: UGC dataset shape: (32, 41)\n",
      "UMPQ: News dataset shape: (0, 0)\n",
      "UMPQ: UGC dataset shape: (30, 40)\n",
      "ZION: News dataset shape: (1, 2)\n",
      "ZION: UGC dataset shape: (31, 35)\n",
      "\n",
      "\n",
      "2020-10-23\n",
      "Found large change stocks: {'HSBC', 'AGIO', 'CCI', 'UMC', 'ALGN'}\n",
      "(5, 10)\n",
      "AGIO: News dataset shape: (0, 2)\n",
      "AGIO: UGC dataset shape: (30, 38)\n",
      "ALGN: News dataset shape: (0, 2)\n",
      "ALGN: UGC dataset shape: (30, 38)\n",
      "CCI: News dataset shape: (1, 2)\n",
      "CCI: UGC dataset shape: (30, 38)\n",
      "HSBC: News dataset shape: (0, 2)\n",
      "HSBC: UGC dataset shape: (31, 38)\n",
      "UMC: News dataset shape: (1, 2)\n",
      "UMC: UGC dataset shape: (33, 39)\n",
      "\n",
      "\n",
      "2020-10-26\n",
      "Found large change stocks: {'CAJ', 'DNKN'}\n",
      "(2, 10)\n",
      "CAJ: News dataset shape: (23, 2)\n",
      "CAJ: UGC dataset shape: (30, 36)\n",
      "DNKN: News dataset shape: (18, 2)\n",
      "DNKN: UGC dataset shape: (94, 41)\n",
      "\n",
      "\n",
      "2020-10-27\n",
      "Found large change stocks: {'HSBC', 'UMPQ', 'LLY', 'RARE', 'CAJ', 'CR', 'MT'}\n",
      "(7, 10)\n",
      "CAJ: News dataset shape: (64, 2)\n",
      "CAJ: UGC dataset shape: (31, 38)\n",
      "CR: News dataset shape: (24, 2)\n",
      "CR: UGC dataset shape: (30, 35)\n",
      "HSBC: News dataset shape: (4, 2)\n",
      "HSBC: UGC dataset shape: (37, 36)\n",
      "LLY: News dataset shape: (87, 2)\n",
      "LLY: UGC dataset shape: (80, 41)\n",
      "MT: News dataset shape: (1, 2)\n",
      "MT: UGC dataset shape: (30, 38)\n",
      "RARE: News dataset shape: (2, 2)\n",
      "RARE: UGC dataset shape: (31, 40)\n",
      "UMPQ: News dataset shape: (0, 0)\n",
      "UMPQ: UGC dataset shape: (30, 38)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "\n",
    "    Loading News and UGC data\n",
    "\n",
    "        stocks_key_words_dict\n",
    "        large_stock_df_dict\n",
    "    \n",
    "    Results: News and UGC\n",
    "        res_news_df_dict\n",
    "        res_ugc_df_dict\n",
    "\n",
    "    \n",
    "'''\n",
    "# stocks_key_words_dict\n",
    "stocks_key_words_dict = {}\n",
    "del_words = ['Ltd', 'Inc', 'Corp', 'Holdings', 'LLC', 'Corporation', 'PLC',\n",
    "             'HOLDERs', 'Co', 'Limited', 'Company',\n",
    "             'Providers', 'group', 'com', 'Brands']\n",
    "del_words = [w.lower() for w in del_words]\n",
    "\n",
    "w_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# large_stock_df_dict\n",
    "large_stock_df_dict = {}\n",
    "\n",
    "# results: News and UGC\n",
    "res_news_df_dict = {}\n",
    "res_ugc_df_dict = {}\n",
    "\n",
    "for day in dates_filename_list:\n",
    "    print(day)\n",
    "    \n",
    "    if unique_stocks_d[day] == set():\n",
    "        print('No large change stock found in day {}'.format(day))\n",
    "    else:\n",
    "        print('Found large change stocks:', unique_stocks_d[day])\n",
    "        \n",
    "        large_stock_df = get_large_stock_df(day, unique_stocks_d, first_large_change_d)\n",
    "        large_stock_df_dict[day] = large_stock_df\n",
    "\n",
    "        for s in sorted(list(unique_stocks_d[day])):\n",
    "            if s not in stocks_key_words_dict:\n",
    "                tmp_words = []\n",
    "                tmp_words.append(s.lower())\n",
    "\n",
    "                tmp_names = [w_lemmatizer.lemmatize(w.lower()) for w in re.findall(r'\\w+', large_stock_df[large_stock_df['Symbol'] == s]['Name'].values[0]) \\\n",
    "                             if w.lower() not in del_words]\n",
    "                tmp_words.append(' '.join(tmp_names))\n",
    "\n",
    "                tmp_words = list(set(tmp_words))\n",
    "                stocks_key_words_dict[s] = tmp_words\n",
    "\n",
    "        tmp_path = os.path.join(os.path.join(os.path.join(parent_dir, 'mid_large_cap_stocks'), \n",
    "                 day), 'threshold_{}/'.format(top_p[0]))\n",
    "\n",
    "        res_news_df_dict[day], \\\n",
    "        res_ugc_df_dict[day] = get_news_ugc_data(day, tmp_path, unique_stocks_d)\n",
    "\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from collections import Counter\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "del_words.extend(['$', '\\n', '\\n\\n', '|'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-02 HSBC\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['hsbc']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day = dates_filename_list[0]\n",
    "s = sorted(list(unique_stocks_d[day]))[0]\n",
    "print(day, s)\n",
    "\n",
    "stocks_key_words_dict[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Word frequency:\n",
    "        News\n",
    "    \n",
    "        UGC\n",
    "    \n",
    "'''\n",
    "# news\n",
    "tmp_news_title = res_news_df_dict[day][s]['title'].apply(lambda x: nlp(x))\n",
    "\n",
    "news_words = [token.text for sent in tmp_news_title for token in sent if not token.is_stop and not token.is_punct and not token.is_space]\n",
    "news_words = [w_lemmatizer.lemmatize(w.lower()) for w in news_words if w.lower() not in del_words]\n",
    "\n",
    "news_word_freq = Counter(news_words)\n",
    "\n",
    "# UGC\n",
    "tmp_ugc_data = res_ugc_df_dict[day][s]['body'].apply(lambda x: nlp(x))\n",
    "\n",
    "ugc_words = [token.text for sent in tmp_ugc_data for token in sent if not token.is_stop and not token.is_punct and not token.is_space]\n",
    "ugc_words = [w_lemmatizer.lemmatize(w.lower()) for w in ugc_words if w.lower() not in del_words]\n",
    "\n",
    "ugc_word_freq = Counter(ugc_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hsbc', 3),\n",
       " ('bank', 3),\n",
       " ('market', 2),\n",
       " ('nyse', 1),\n",
       " ('currently', 1),\n",
       " ('99.45', 1),\n",
       " ('52-week', 1),\n",
       " ('high', 1),\n",
       " ('upside', 1),\n",
       " ('potential', 1),\n",
       " ('surprise', 1),\n",
       " ('marketing', 1),\n",
       " ('sentinel', 1),\n",
       " ('oman', 1),\n",
       " ('card', 1),\n",
       " ('payment', 1),\n",
       " ('report-', 1),\n",
       " ('growth', 1),\n",
       " ('opportunity', 1),\n",
       " ('company', 1)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_word_freq.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hsbc', 37),\n",
       " ('pm', 11),\n",
       " ('adr', 7),\n",
       " ('short', 6),\n",
       " ('stock', 6),\n",
       " ('form', 4),\n",
       " ('6-k', 4),\n",
       " ('filed', 4),\n",
       " ('sentiment', 4),\n",
       " ('close', 3),\n",
       " ('li', 3),\n",
       " ('15', 3),\n",
       " ('jpm', 3),\n",
       " ('negative', 3),\n",
       " ('social', 3),\n",
       " ('medium', 3),\n",
       " ('https://socialsentiment.io/stocks/symbol/hsbc/', 3),\n",
       " ('week', 3),\n",
       " ('+', 3),\n",
       " ('soon', 2)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ugc_word_freq.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PoS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_words_noun_verb_adj = [(token.text, token.pos_) for sent in tmp_news_title for token in sent \\\n",
    " if not token.is_stop and not token.is_punct and not token.is_space \\\n",
    " and token.pos_ in ('VERB', 'NOUN', 'ADJ')]\n",
    "news_words_noun_verb_adj = [(w_lemmatizer.lemmatize(w.lower()), t) for w, t in news_words_noun_verb_adj \\\n",
    "                           if w.lower() not in del_words]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('high', 'ADJ'), 1),\n",
       " (('surprise', 'VERB'), 1),\n",
       " (('marketing', 'NOUN'), 1),\n",
       " (('sentinel', 'NOUN'), 1),\n",
       " (('market', 'NOUN'), 1)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(news_words_noun_verb_adj).most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
