{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from json.decoder import JSONDecodeError\n",
    "from pandas import json_normalize\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from pandas_datareader import data as pdr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'2020-11-03' < '2020-10-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_results(day, top_p, parent_dir):\n",
    "    sub_industry = 'mid_large_cap_stocks'\n",
    "\n",
    "    tmp_path = os.path.join(os.path.join(parent_dir, sub_industry),  day)\n",
    "\n",
    "    try:\n",
    "        os.chdir(tmp_path)\n",
    "    except:\n",
    "        print('No such directory found!')\n",
    "\n",
    "    print(tmp_path)\n",
    "\n",
    "    '''\n",
    "        get stock prices and large change stock list\n",
    "    '''\n",
    "    large_change_stocks_all_original = {}\n",
    "    current_prices_original = {}\n",
    "\n",
    "    for p in top_p:\n",
    "        current_path = os.path.join(tmp_path, 'threshold_{}'.format(p))\n",
    "\n",
    "        with open(current_path + '/1_large_change_stocks.json') as f:\n",
    "            large_change_stocks_all_original[p] = json.load(f)\n",
    "\n",
    "        with open(current_path + '/2_current_prices.json') as f:\n",
    "            current_prices_original[p] = json.load(f)\n",
    "\n",
    "    print('iterations: {}'.format(len(current_prices_original[top_p[0]].keys())))\n",
    "\n",
    "    \n",
    "    if day < '2020-11-01':\n",
    "        open_time = datetime.datetime(2020, int(day.split('-')[1]), \\\n",
    "                                      int(day.split('-')[2]), 21, 31).isoformat()\n",
    "    else:\n",
    "        open_time = datetime.datetime(2020, int(day.split('-')[1]), \\\n",
    "                                  int(day.split('-')[2]), 22, 31).isoformat()\n",
    "\n",
    "    print('Open time: {}'.format(open_time))\n",
    "\n",
    "    if len([k for k, v in large_change_stocks_all_original[top_p[0]].items() if v != []]) == 0:\n",
    "        print('no large change stocks!')\n",
    "    elif len([k for k, v in large_change_stocks_all_original[top_p[0]].items() if v != []]) == 1:\n",
    "        iter_1st = [k for k, v in large_change_stocks_all_original[top_p[0]].items() if v != []][0]\n",
    "        print(iter_1st)\n",
    "\n",
    "        print('Time of 1st iteration: {}'.format(large_change_stocks_all_original[top_p[0]][iter_1st][0][3]))\n",
    "        large_change_stocks_all = large_change_stocks_all_original.copy()\n",
    "        current_prices = current_prices_original.copy()\n",
    "\n",
    "        if large_change_stocks_all_original[top_p[0]][iter_1st][0][3] < open_time:\n",
    "            # remove 1st iteration before 09:30\n",
    "            print('Time of 1st iteration before 09:30:00...')\n",
    "            print('Remove 1st iteration in large change stocks dataset')\n",
    "\n",
    "            large_change_stocks_all[top_p[0]][iter_1st] = []\n",
    "\n",
    "    elif len([k for k, v in large_change_stocks_all_original[top_p[0]].items() if v != []]) >= 2:\n",
    "        iter_1st = [k for k, v in large_change_stocks_all_original[top_p[0]].items() if v != []][0]\n",
    "        iter_2nd = [k for k, v in large_change_stocks_all_original[top_p[0]].items() if v != []][1]\n",
    "        print(iter_1st, iter_2nd)\n",
    "        print('Time of 1st iteration: {}'.format(large_change_stocks_all_original[top_p[0]][iter_1st][0][3]))\n",
    "        large_change_stocks_all = large_change_stocks_all_original.copy()\n",
    "        current_prices = current_prices_original.copy()\n",
    "\n",
    "        if large_change_stocks_all_original[top_p[0]][iter_1st][0][3] < open_time:\n",
    "            # remove 1st iteration before 09:30\n",
    "            print('Time of 1st iteration before 09:30:00...')\n",
    "            print('Remove 1st iteration in large change stocks dataset')\n",
    "\n",
    "            large_change_stocks_all[top_p[0]][iter_1st] = []\n",
    "\n",
    "        if current_prices_original[top_p[0]][iter_1st][0][1] < open_time and current_prices_original[top_p[0]][iter_2nd][0][1] < open_time:\n",
    "            print('Time of 1st and 2nd iterations before 09:30:00...')\n",
    "            print('Remove 1st iteration in current prices dataset')\n",
    "\n",
    "            current_prices[top_p[0]][iter_1st] = []   \n",
    "    \n",
    "    return current_prices, large_change_stocks_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_large_change_times(current_stock, large_times):\n",
    "    first_large_change = {}\n",
    "    for p in top_p:\n",
    "        first_large_change[p] = {}\n",
    "\n",
    "        n_len = len(large_times[p])\n",
    "        for i in range(n_len):\n",
    "            if current_stock == large_times[p][i][0]:\n",
    "                first_large_change[p][current_stock] = (large_times[p][i][3], large_times[p][i][1], large_times[p][i][2])\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "    return first_large_change\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "   \n",
    "   Get opening price as the first data point\n",
    "        \n",
    "'''\n",
    "from pandas_datareader import data as pdr\n",
    "\n",
    "def get_stock_openprice(unique_stocks, day):\n",
    "    \n",
    "    large_stock_openprice = {}\n",
    "    large_stock_hist = {}\n",
    "\n",
    "    for s in sorted(list(unique_stocks)):\n",
    "        tmp_hist = pdr.get_data_yahoo(s, start = day, end = day)\n",
    "        large_stock_hist[s] = tmp_hist\n",
    "        tmp_hist = tmp_hist[~tmp_hist.index.duplicated(keep='first')]\n",
    "\n",
    "        large_stock_openprice[s] = tmp_hist.loc[day]\n",
    "\n",
    "    return large_stock_openprice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stock_prices(day, top_p, df_thre_at_q,\n",
    "                     current_prices, large_change_stocks_all, \n",
    "                     pic_path):\n",
    "\n",
    "    if len([k for k, v in large_change_stocks_all[top_p[0]].items() if v != []]) == 0:\n",
    "        print('No large change stock found!')\n",
    "    else:\n",
    "\n",
    "        '''\n",
    "           stocks_list: \n",
    "           n_stocks: number of stocks\n",
    "        '''\n",
    "\n",
    "        stocks_list = [x[0] for x in current_prices[top_p[0]]['2']]\n",
    "        n_stocks = len(stocks_list)\n",
    "\n",
    "        print('Number of stocks in the list:', n_stocks)\n",
    "\n",
    "\n",
    "        '''\n",
    "            Get individual stock prices\n",
    "                - individual_stock_price: \n",
    "                    - key: stock symbol\n",
    "                    - value: key - timestamp, value - stock price\n",
    "        '''\n",
    "        individual_stock_price = {}\n",
    "        for s in stocks_list:\n",
    "        #     print(s)\n",
    "            individual_stock_price[s] = {}\n",
    "\n",
    "            for p in top_p:\n",
    "                n_cnts = len(current_prices[p].keys())\n",
    "\n",
    "                for k, v in current_prices[p].items():\n",
    "                    for i in v:\n",
    "                        if i[0] == s:\n",
    "                            individual_stock_price[s][datetime.datetime.strptime(i[1], \"%Y-%m-%dT%H:%M:%S.%f\").isoformat()] = \\\n",
    "                                float(str(i[2]).replace(',',''))\n",
    "\n",
    "\n",
    "        '''\n",
    "            large_times:\n",
    "                key: 95th\n",
    "                value: (symbol, price, %change, time)\n",
    "            large_stocks:\n",
    "                key: 95th\n",
    "                value: set of large change stocks\n",
    "        '''\n",
    "        large_times = {}\n",
    "        large_stocks = {}\n",
    "\n",
    "        for p in top_p:\n",
    "\n",
    "            large_times[p] = []\n",
    "            large_stocks[p] = []\n",
    "\n",
    "            for k, v in large_change_stocks_all[p].items():\n",
    "                if len(v) > 0:\n",
    "                    large_stocks[p].extend([x[0] for x in v])\n",
    "                    large_times[p].extend([(x[0], float(x[1].replace(',', '')), x[2], datetime.datetime.strptime(x[3], \"%Y-%m-%dT%H:%M:%S.%f\").isoformat()) for x in v])\n",
    "\n",
    "            large_stocks[p] = set(large_stocks[p])\n",
    "\n",
    "        print(large_stocks[top_p[0]], large_times[top_p[0]][0])\n",
    "\n",
    "\n",
    "        '''\n",
    "            first_large_change: \n",
    "                key: symbol\n",
    "                value: dict of \n",
    "                    key: 95th\n",
    "                    value: k=symbol, v=(time, price, %change)\n",
    "        '''\n",
    "\n",
    "        first_large_change = {}\n",
    "\n",
    "        unique_stocks = set()\n",
    "        for k,v in large_stocks.items():\n",
    "            unique_stocks = unique_stocks.union(v)\n",
    "\n",
    "        for s in sorted(list(unique_stocks)):\n",
    "            first_large_change[s] = get_first_large_change_times(s, large_times)\n",
    "\n",
    "        print(first_large_change)\n",
    "\n",
    "\n",
    "        '''\n",
    "            large_stock_price:\n",
    "                key: symbol\n",
    "                value: df-stock price for each iteration, index=time, value=price\n",
    "        '''\n",
    "        large_stock_price = {}\n",
    "        for k, v in individual_stock_price.items():\n",
    "            if k in unique_stocks:\n",
    "                large_stock_price[k] = v\n",
    "\n",
    "\n",
    "        for k, v in large_stock_price.items():\n",
    "            large_stock_price[k] = pd.DataFrame(v.values(), index=v.keys(), columns=[k])\n",
    "            large_stock_price[k].sort_index(inplace=True)\n",
    "\n",
    "        print(large_stock_price.keys())\n",
    "\n",
    "\n",
    "        '''\n",
    "            Stock price change plot:\n",
    "                - red dot: first detect large price change\n",
    "        '''\n",
    "\n",
    "        large_stock_price_copy = large_stock_price.copy()\n",
    "\n",
    "        ####\n",
    "        large_stock_openprice = get_stock_openprice(unique_stocks, day)\n",
    "        \n",
    "        if day < '2020-11-01':\n",
    "            open_time = datetime.datetime(2020, int(day.split('-')[1]), int(day.split('-')[2]), 21, 30).isoformat()\n",
    "        else:\n",
    "            open_time = datetime.datetime(2020, int(day.split('-')[1]), int(day.split('-')[2]), 22, 30).isoformat()\n",
    "\n",
    "        n_col = ['ro', 'bo', 'yo']\n",
    "\n",
    "        if not os.path.exists(pic_path):\n",
    "            os.mkdir(pic_path)\n",
    "\n",
    "        with PdfPages('{}/all_stocks_price_plot_{}.pdf'.format(pic_path, day)) as pdf:\n",
    "            for s in sorted(list(unique_stocks)):\n",
    "                p_time = []\n",
    "                for p in top_p:\n",
    "                    if first_large_change[s][p]:\n",
    "                        p_time.append((p, first_large_change[s][p][s]))\n",
    "                print(s, p_time)\n",
    "\n",
    "                if large_stock_price[s].index[0] > open_time:\n",
    "                    # adding open price in the stock price list \n",
    "                    large_stock_price_copy[s] = pd.concat([pd.DataFrame({s: large_stock_openprice[s].loc['Open']}, index=[open_time]), \\\n",
    "                              large_stock_price_copy[s]])\n",
    "                \n",
    "                large_stock_price_copy[s] = large_stock_price_copy[s].sort_index()\n",
    "\n",
    "                # get length of stock prices\n",
    "                p_len = len(large_stock_price_copy[s].index)\n",
    "\n",
    "                insert_index = [(p_time[i][0], sum(p_time[i][1][0] > large_stock_price_copy[s].index)) for i in range(len(p_time))]\n",
    "                print(insert_index)\n",
    "\n",
    "                if insert_index[0][1] > 1:\n",
    "\n",
    "                    fig = plt.figure(figsize=(7, 5))\n",
    "                    plt.plot(range(p_len), large_stock_price_copy[s].values, 'o-')\n",
    "\n",
    "                    dot = {}\n",
    "                    for i in range(len(p_time)):\n",
    "                        dot[i], = plt.plot(insert_index[i][1]-1, p_time[i][1][1], n_col[i])\n",
    "\n",
    "                    plt.legend(list(dot.values()), ['Percentage Change: {}%'.format(p_time[i][1][2]) for p in p_time], loc = 4)\n",
    "                    plt.xlabel('Iteration')\n",
    "                    plt.ylabel('Price')\n",
    "                    plt.title('{}: {}'.format(day, s))\n",
    "                    txt = \"Stock {}: detect {}% change (threshold {}%) \\n at time {} with price ${}\".format(s, \n",
    "                                         p_time[0][1][2], round(df_thre_at_q[df_thre_at_q['symbols']==s]['threshold_at_{}'.format(top_p[0])].values[0], 2), \n",
    "                                         p_time[0][1][0], p_time[0][1][1])\n",
    "                    plt.text(0.05, 0.95, txt, transform=fig.transFigure, size = 8)\n",
    "                    pdf.savefig(fig)\n",
    "                    plt.close()\n",
    "\n",
    "\n",
    "    \n",
    "        return unique_stocks, first_large_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2020-10-02', '2020-10-05', '2020-10-06', '2020-10-07', '2020-10-13', '2020-10-14', '2020-10-15', '2020-10-16', '2020-10-19', '2020-10-20', '2020-10-21', '2020-10-22', '2020-10-23', '2020-10-26', '2020-10-27', '2020-10-28', '2020-10-29', '2020-10-30', '2020-11-02', '2020-11-03']\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    dates_filename_list: \n",
    "    top_p: \n",
    "        95th percentile as the threshold to detect a stock with large change\n",
    "    sub_industry: \n",
    "        focus on mid-cap and large-cap companies\n",
    "\n",
    "'''\n",
    "parent_dir = '/Users/lin/Desktop/Stock-Market-Analysis/'\n",
    "\n",
    "top_p = [95]\n",
    "\n",
    "dates_filename_list = sorted([filename for filename in os.listdir('{}mid_large_cap_stocks/'.format(parent_dir)) \n",
    "                              if filename.startswith('2020')])\n",
    "print(dates_filename_list)\n",
    "\n",
    "\n",
    "df_thre_at_q = pd.read_csv('{}df_thre_at_q{}.csv'.format(parent_dir,\\\n",
    "                                                               top_p[0]), index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2020-10-19', '2020-10-29', '2020-10-30', '2020-11-02', '2020-11-03']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_pics_list = glob.glob('{}/stock_price_figures/all_stocks_price_plot_*.pdf'.format(parent_dir))\n",
    "\n",
    "current_pics_dates = [x.split('all_stocks_price_plot_')[1].split('.pdf')[0] \\\n",
    "                      for x in current_pics_list]\n",
    "\n",
    "new_dates_list = [x for x in dates_filename_list if x not in current_pics_dates]\n",
    "new_dates_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-03\n",
      "/Users/lin/Desktop/Stock-Market-Analysis/mid_large_cap_stocks/2020-11-03\n",
      "iterations: 26\n",
      "Open time: 2020-11-03T22:31:00\n",
      "1 2\n",
      "Time of 1st iteration: 2020-11-03T22:33:35.347729\n",
      "Number of stocks in the list: 167\n",
      "{'CDK', 'MMP', 'CHTR', 'EPD', 'JKHY', 'IT', 'COP', 'IMO', 'PBR', 'CAJ', 'KLAC', 'PAA'} ('CAJ', 17.77, 6.32, '2020-11-03T22:33:35.347729')\n",
      "{'CAJ': {95: {'CAJ': ('2020-11-03T22:33:35.347729', 17.77, 6.32)}}, 'CDK': {95: {'CDK': ('2020-11-03T22:33:35.347729', 44.03, 7.640000000000001)}}, 'CHTR': {95: {'CHTR': ('2020-11-03T22:33:35.347729', 588.43, 50.0)}}, 'COP': {95: {'COP': ('2020-11-04T01:45:05.919784', 29.49, 4.590909090909091)}}, 'EPD': {95: {'EPD': ('2020-11-03T23:48:54.509596', 16.57, 7.0)}}, 'IMO': {95: {'IMO': ('2020-11-03T23:48:54.509596', 14.21, 12.692307692307692)}}, 'IT': {95: {'IT': ('2020-11-03T22:33:35.347729', 125.02, 15.399999999999999)}}, 'JKHY': {95: {'JKHY': ('2020-11-03T22:33:35.347729', 151.77, 8.48)}}, 'KLAC': {95: {'KLAC': ('2020-11-03T22:33:35.347729', 202.23, 9.24)}}, 'MMP': {95: {'MMP': ('2020-11-03T23:48:54.509596', 36.45, 12.307692307692308)}}, 'PAA': {95: {'PAA': ('2020-11-04T01:14:17.755429', 6.55, 37.5)}}, 'PBR': {95: {'PBR': ('2020-11-03T23:34:26.535535', 6.93, 7.970588235294117)}}}\n",
      "dict_keys(['CAJ', 'CDK', 'CHTR', 'COP', 'EPD', 'IMO', 'IT', 'JKHY', 'KLAC', 'MMP', 'PAA', 'PBR'])\n",
      "CAJ [(95, ('2020-11-03T22:33:35.347729', 17.77, 6.32))]\n",
      "[(95, 1)]\n",
      "CDK [(95, ('2020-11-03T22:33:35.347729', 44.03, 7.640000000000001))]\n",
      "[(95, 1)]\n",
      "CHTR [(95, ('2020-11-03T22:33:35.347729', 588.43, 50.0))]\n",
      "[(95, 1)]\n",
      "COP [(95, ('2020-11-04T01:45:05.919784', 29.49, 4.590909090909091))]\n",
      "[(95, 14)]\n",
      "EPD [(95, ('2020-11-03T23:48:54.509596', 16.57, 7.0))]\n",
      "[(95, 6)]\n",
      "IMO [(95, ('2020-11-03T23:48:54.509596', 14.21, 12.692307692307692))]\n",
      "[(95, 6)]\n",
      "IT [(95, ('2020-11-03T22:33:35.347729', 125.02, 15.399999999999999))]\n",
      "[(95, 1)]\n",
      "JKHY [(95, ('2020-11-03T22:33:35.347729', 151.77, 8.48))]\n",
      "[(95, 1)]\n",
      "KLAC [(95, ('2020-11-03T22:33:35.347729', 202.23, 9.24))]\n",
      "[(95, 1)]\n",
      "MMP [(95, ('2020-11-03T23:48:54.509596', 36.45, 12.307692307692308))]\n",
      "[(95, 6)]\n",
      "PAA [(95, ('2020-11-04T01:14:17.755429', 6.55, 37.5))]\n",
      "[(95, 13)]\n",
      "PBR [(95, ('2020-11-03T23:34:26.535535', 6.93, 7.970588235294117))]\n",
      "[(95, 6)]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Stock price movement visualization\n",
    "\n",
    "'''\n",
    "current_prices_d = {}\n",
    "large_change_stocks_all_d ={}\n",
    "unique_stocks_d = {}\n",
    "first_large_change_d = {}\n",
    "\n",
    "# dates_filename_list\n",
    "for day in ['2020-11-03']:\n",
    "    print(day)\n",
    "    current_prices_d[day], \\\n",
    "    large_change_stocks_all_d[day] = preprocess_results(day, top_p,\n",
    "                                                       parent_dir)\n",
    "    if len([k for k, v in large_change_stocks_all_d[day][top_p[0]].items() if v != []]) == 0:\n",
    "        print('No large change stock found!')\n",
    "        unique_stocks_d[day] = set()\n",
    "        first_large_change_d[day] = dict()\n",
    "    else:\n",
    "        unique_stocks_d[day], \\\n",
    "        first_large_change_d[day] = plot_stock_prices(day, top_p, df_thre_at_q, \n",
    "                                                     current_prices_d[day], large_change_stocks_all_d[day],\n",
    "                                                     pic_path=os.path.join(parent_dir, 'stock_price_figures'))\n",
    "    \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## News and UGC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "   \n",
    "   Get opening price as the first data point\n",
    "        \n",
    "'''\n",
    "\n",
    "\n",
    "def get_large_stock_df(day, unique_stocks_d, first_large_change_d):\n",
    "    \n",
    "\n",
    "    large_stock_openprice = {}\n",
    "    large_stock_hist = {}\n",
    "\n",
    "    for s in sorted(list(unique_stocks_d[day])):\n",
    "        tmp_hist = pdr.get_data_yahoo(s, start = day, end = day)\n",
    "        large_stock_hist[s] = tmp_hist\n",
    "        tmp_hist = tmp_hist[~tmp_hist.index.duplicated(keep='first')]\n",
    "\n",
    "        large_stock_openprice[s] = tmp_hist.loc[day]\n",
    "\n",
    "\n",
    "    large_stock_df = pd.DataFrame(0, index=sorted(list(unique_stocks_d[day])), \n",
    "                                  columns=large_stock_hist[s].columns)\n",
    "    large_stock_df['Thre_at_{}'.format(top_p[0])] = 0\n",
    "    large_stock_df['First_Percent_Change'] = 0\n",
    "    large_stock_df['First_Stock_Price'] = 0\n",
    "\n",
    "    for s in sorted(list(unique_stocks_d[day])):\n",
    "        large_stock_df.loc[s] = large_stock_hist[s].loc[day]\n",
    "        large_stock_df.loc[s, 'Thre_at_{}'.format(top_p[0])] = df_thre_at_q[df_thre_at_q['symbols']==s]['threshold_at_{}'.format(top_p[0])].values\n",
    "        large_stock_df.loc[s, 'First_Percent_Change'] = first_large_change_d[day][s][top_p[0]][s][2]\n",
    "        large_stock_df.loc[s, 'First_Stock_Price'] = first_large_change_d[day][s][top_p[0]][s][1]\n",
    "\n",
    "    large_stock_df = large_stock_df.assign(Total_Percent_Change = lambda x: \n",
    "                                                           round((x['Close'] - x['Open'])/x['Open']*100 ,2))\n",
    "\n",
    "    print(large_stock_df.shape)\n",
    "\n",
    "    large_stock_df.reset_index(inplace=True)\n",
    "    large_stock_df.rename(columns={'index': 'Symbol'}, inplace=True)\n",
    "\n",
    "    large_stock_df = pd.merge(large_stock_df, stocks_midlargeCap_webscrape_df,\n",
    "                        how = 'left', on = 'Symbol')\n",
    "\n",
    "    return large_stock_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Get News and UGC dataframe for each day\n",
    "'''\n",
    "\n",
    "\n",
    "def get_news_ugc_data(day, tmp_path, unique_stocks_d):\n",
    "\n",
    "    res_news_df = {}\n",
    "    res_ugc_df = {}\n",
    "\n",
    "    for s in sorted(list(unique_stocks_d[day])):\n",
    "\n",
    "        news_filename_list = glob.glob(os.path.join(tmp_path, '{}/News_*.json'.format(s)))\n",
    "        ugc_filename_list = glob.glob(os.path.join(tmp_path, '{}/UGC_*.json'.format(s)))\n",
    "\n",
    "        res_news_dict = {}\n",
    "        res_ugc_dict = {}\n",
    "\n",
    "        for news_file in news_filename_list:\n",
    "\n",
    "            with open(news_file) as f:\n",
    "                try:\n",
    "                    res_news_dict[news_file.split('{}/threshold_{}/{}/'.format(day, top_p[0], s))[1]] = json.load(f)\n",
    "                except JSONDecodeError:\n",
    "                    pass\n",
    "            f.close()\n",
    "\n",
    "        res_news_df[s] = pd.DataFrame({'published': [item['published'] for k, v in res_news_dict.items() for item in v],\n",
    "                                    'title':[item['title'] for k, v in res_news_dict.items() for item in v]})\n",
    "        # drop duplicates by title:\n",
    "        res_news_df[s] = res_news_df[s].drop_duplicates('title').reset_index(drop = True)\n",
    "\n",
    "        # drop news that do not contain stock key-words in title:\n",
    "        res_news_df[s] = res_news_df[s][res_news_df[s]['title'].map(lambda x: \\\n",
    "                 any(word in x.lower() for word in stocks_key_words_dict[s]))].reset_index(drop=True)\n",
    "\n",
    "        print('{}: News dataset shape: {}'.format(s, res_news_df[s].shape))\n",
    "\n",
    "        for ugc_file in ugc_filename_list:\n",
    "\n",
    "            with open(ugc_file) as f:\n",
    "                try:\n",
    "                    res_ugc_dict[ugc_file.split('{}/threshold_{}/{}/'.format(day, top_p[0], s))[1]] = json.load(f)\n",
    "                except JSONDecodeError:\n",
    "                    pass\n",
    "            f.close()\n",
    "\n",
    "        res_ugc_df[s] = []\n",
    "        for k, v in res_ugc_dict.items():\n",
    "            tmp_df = pd.DataFrame.from_dict(json_normalize(v['messages']), orient='columns')\n",
    "            res_ugc_df[s].append(tmp_df)\n",
    "\n",
    "        res_ugc_df[s] = pd.concat(res_ugc_df[s])\n",
    "        # drop duplicates by message id:\n",
    "        res_ugc_df[s] = res_ugc_df[s].drop_duplicates('id').reset_index(drop = True)\n",
    "\n",
    "        print('{}: UGC dataset shape: {}'.format(s, res_ugc_df[s].shape))\n",
    "    \n",
    "    return res_news_df, res_ugc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(167, 11)\n"
     ]
    }
   ],
   "source": [
    "stocks_midlargeCap_webscrape_df = pd.read_csv('{}/df_stocks_midlargeCap_webscrape.csv'.format(parent_dir), \n",
    "                                              index_col=0)\n",
    "\n",
    "print(stocks_midlargeCap_webscrape_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-02\n",
      "Found large change stocks: {'HSBC', 'LSCC'}\n",
      "(2, 10)\n",
      "HSBC: News dataset shape: (2, 2)\n",
      "HSBC: UGC dataset shape: (30, 42)\n",
      "LSCC: News dataset shape: (0, 2)\n",
      "LSCC: UGC dataset shape: (30, 34)\n",
      "\n",
      "\n",
      "2020-10-05\n",
      "Found large change stocks: {'EPR', 'LSCC', 'MYOK', 'REGN', 'AGIO', 'AQN', 'ZION', 'ROK', 'PBR', 'WIT', 'MRVL', 'STLD', 'UMC'}\n",
      "(13, 10)\n",
      "AGIO: News dataset shape: (3, 2)\n",
      "AGIO: UGC dataset shape: (30, 40)\n",
      "AQN: News dataset shape: (0, 2)\n",
      "AQN: UGC dataset shape: (30, 40)\n",
      "EPR: News dataset shape: (9, 2)\n",
      "EPR: UGC dataset shape: (61, 41)\n",
      "LSCC: News dataset shape: (0, 2)\n",
      "LSCC: UGC dataset shape: (30, 34)\n",
      "MRVL: News dataset shape: (5, 2)\n",
      "MRVL: UGC dataset shape: (36, 41)\n",
      "MYOK: News dataset shape: (36, 2)\n",
      "MYOK: UGC dataset shape: (114, 42)\n",
      "PBR: News dataset shape: (0, 0)\n",
      "PBR: UGC dataset shape: (30, 43)\n",
      "REGN: News dataset shape: (14, 2)\n",
      "REGN: UGC dataset shape: (428, 43)\n",
      "ROK: News dataset shape: (12, 2)\n",
      "ROK: UGC dataset shape: (32, 34)\n",
      "STLD: News dataset shape: (0, 2)\n",
      "STLD: UGC dataset shape: (30, 40)\n",
      "UMC: News dataset shape: (1, 2)\n",
      "UMC: UGC dataset shape: (36, 42)\n",
      "WIT: News dataset shape: (38, 2)\n",
      "WIT: UGC dataset shape: (38, 40)\n",
      "ZION: News dataset shape: (0, 0)\n",
      "ZION: UGC dataset shape: (30, 36)\n",
      "\n",
      "\n",
      "2020-10-06\n",
      "Found large change stocks: {'WIT', 'CAJ'}\n",
      "(2, 10)\n",
      "CAJ: News dataset shape: (6, 2)\n",
      "CAJ: UGC dataset shape: (30, 36)\n",
      "WIT: News dataset shape: (1, 2)\n",
      "WIT: UGC dataset shape: (30, 40)\n",
      "\n",
      "\n",
      "2020-10-07\n",
      "Found large change stocks: {'HSBC', 'LLY', 'NFLX', 'NVCR', 'SIRI', 'MT', 'QDEL', 'WIT', 'SRPT', 'UMC', 'BMY'}\n",
      "(11, 10)\n",
      "BMY: News dataset shape: (9, 2)\n",
      "BMY: UGC dataset shape: (47, 40)\n",
      "HSBC: News dataset shape: (1, 2)\n",
      "HSBC: UGC dataset shape: (32, 42)\n",
      "LLY: News dataset shape: (9, 2)\n",
      "LLY: UGC dataset shape: (43, 40)\n",
      "MT: News dataset shape: (3, 2)\n",
      "MT: UGC dataset shape: (32, 40)\n",
      "NFLX: News dataset shape: (183, 2)\n",
      "NFLX: UGC dataset shape: (208, 43)\n",
      "NVCR: News dataset shape: (0, 2)\n",
      "NVCR: UGC dataset shape: (51, 43)\n",
      "QDEL: News dataset shape: (2, 2)\n",
      "QDEL: UGC dataset shape: (56, 42)\n",
      "SIRI: News dataset shape: (19, 2)\n",
      "SIRI: UGC dataset shape: (52, 40)\n",
      "SRPT: News dataset shape: (1, 2)\n",
      "SRPT: UGC dataset shape: (33, 42)\n",
      "UMC: News dataset shape: (5, 2)\n",
      "UMC: UGC dataset shape: (40, 43)\n",
      "WIT: News dataset shape: (41, 2)\n",
      "WIT: UGC dataset shape: (32, 40)\n",
      "\n",
      "\n",
      "2020-10-13\n",
      "Found large change stocks: {'HSBC', 'QGEN', 'CAJ', 'EPR', 'LLY', 'F', 'SPOT', 'AB', 'CLX', 'WIT', 'WAT', 'AAPL', 'UMC'}\n",
      "(13, 10)\n",
      "AAPL: News dataset shape: (28, 2)\n",
      "AAPL: UGC dataset shape: (30, 40)\n",
      "AB: News dataset shape: (3, 2)\n",
      "AB: UGC dataset shape: (30, 36)\n",
      "CAJ: News dataset shape: (33, 2)\n",
      "CAJ: UGC dataset shape: (30, 42)\n",
      "CLX: News dataset shape: (0, 2)\n",
      "CLX: UGC dataset shape: (30, 41)\n",
      "EPR: News dataset shape: (1, 2)\n",
      "EPR: UGC dataset shape: (35, 42)\n",
      "F: News dataset shape: (18, 2)\n",
      "F: UGC dataset shape: (30, 42)\n",
      "HSBC: News dataset shape: (0, 2)\n",
      "HSBC: UGC dataset shape: (30, 42)\n",
      "LLY: News dataset shape: (7, 2)\n",
      "LLY: UGC dataset shape: (30, 41)\n",
      "QGEN: News dataset shape: (3, 2)\n",
      "QGEN: UGC dataset shape: (35, 42)\n",
      "SPOT: News dataset shape: (0, 2)\n",
      "SPOT: UGC dataset shape: (33, 43)\n",
      "UMC: News dataset shape: (1, 2)\n",
      "UMC: UGC dataset shape: (30, 40)\n",
      "WAT: News dataset shape: (436, 2)\n",
      "WAT: UGC dataset shape: (38, 40)\n",
      "WIT: News dataset shape: (9, 2)\n",
      "WIT: UGC dataset shape: (30, 40)\n",
      "\n",
      "\n",
      "2020-10-14\n",
      "Found large change stocks: {'PE'}\n",
      "(1, 10)\n",
      "PE: News dataset shape: (31, 2)\n",
      "PE: UGC dataset shape: (31, 40)\n",
      "\n",
      "\n",
      "2020-10-15\n",
      "Found large change stocks: {'TTD', 'TWST', 'HEI'}\n",
      "(3, 10)\n",
      "HEI: News dataset shape: (0, 2)\n",
      "HEI: UGC dataset shape: (30, 36)\n",
      "TTD: News dataset shape: (0, 2)\n",
      "TTD: UGC dataset shape: (104, 43)\n",
      "TWST: News dataset shape: (0, 2)\n",
      "TWST: UGC dataset shape: (33, 43)\n",
      "\n",
      "\n",
      "2020-10-16\n",
      "Found large change stocks: {'JBHT', 'TDC'}\n",
      "(2, 10)\n",
      "JBHT: News dataset shape: (6, 2)\n",
      "JBHT: UGC dataset shape: (52, 42)\n",
      "TDC: News dataset shape: (4, 2)\n",
      "TDC: UGC dataset shape: (32, 34)\n",
      "\n",
      "\n",
      "2020-10-19\n",
      "No large change stock found in day 2020-10-19\n",
      "2020-10-20\n",
      "Found large change stocks: {'MELI', 'CMA'}\n",
      "(2, 10)\n",
      "CMA: News dataset shape: (8, 2)\n",
      "CMA: UGC dataset shape: (35, 39)\n",
      "MELI: News dataset shape: (2, 2)\n",
      "MELI: UGC dataset shape: (50, 43)\n",
      "\n",
      "\n",
      "2020-10-21\n",
      "Found large change stocks: {'AXS', 'CWST', 'NFLX', 'FVRR', 'PINS', 'PE', 'TER', 'COP', 'TWTR', 'TRUP', 'PYPL'}\n",
      "(11, 10)\n",
      "AXS: News dataset shape: (1, 2)\n",
      "AXS: UGC dataset shape: (30, 34)\n",
      "COP: News dataset shape: (17, 2)\n",
      "COP: UGC dataset shape: (31, 40)\n",
      "CWST: News dataset shape: (0, 2)\n",
      "CWST: UGC dataset shape: (33, 36)\n",
      "FVRR: News dataset shape: (1, 2)\n",
      "FVRR: UGC dataset shape: (53, 40)\n",
      "NFLX: News dataset shape: (244, 2)\n",
      "NFLX: UGC dataset shape: (471, 43)\n",
      "PE: News dataset shape: (6, 2)\n",
      "PE: UGC dataset shape: (30, 40)\n",
      "PINS: News dataset shape: (21, 2)\n",
      "PINS: UGC dataset shape: (270, 43)\n",
      "PYPL: News dataset shape: (58, 2)\n",
      "PYPL: UGC dataset shape: (215, 41)\n",
      "TER: News dataset shape: (6, 2)\n",
      "TER: UGC dataset shape: (40, 40)\n",
      "TRUP: News dataset shape: (1, 2)\n",
      "TRUP: UGC dataset shape: (30, 42)\n",
      "TWTR: News dataset shape: (144, 2)\n",
      "TWTR: UGC dataset shape: (183, 43)\n",
      "\n",
      "\n",
      "2020-10-22\n",
      "Found large change stocks: {'AGIO', 'PHM', 'ZION', 'CCI', 'JBLU', 'EFX', 'ALGN', 'UMPQ', 'HBAN', 'TPH', 'PYPL', 'UMC'}\n",
      "(12, 10)\n",
      "AGIO: News dataset shape: (0, 2)\n",
      "AGIO: UGC dataset shape: (36, 40)\n",
      "ALGN: News dataset shape: (24, 2)\n",
      "ALGN: UGC dataset shape: (335, 41)\n",
      "CCI: News dataset shape: (0, 2)\n",
      "CCI: UGC dataset shape: (35, 36)\n",
      "EFX: News dataset shape: (1, 2)\n",
      "EFX: UGC dataset shape: (32, 36)\n",
      "HBAN: News dataset shape: (2, 2)\n",
      "HBAN: UGC dataset shape: (33, 34)\n",
      "JBLU: News dataset shape: (3, 2)\n",
      "JBLU: UGC dataset shape: (41, 38)\n",
      "PHM: News dataset shape: (5, 2)\n",
      "PHM: UGC dataset shape: (32, 38)\n",
      "PYPL: News dataset shape: (9, 2)\n",
      "PYPL: UGC dataset shape: (66, 41)\n",
      "TPH: News dataset shape: (1, 2)\n",
      "TPH: UGC dataset shape: (30, 38)\n",
      "UMC: News dataset shape: (8, 2)\n",
      "UMC: UGC dataset shape: (32, 41)\n",
      "UMPQ: News dataset shape: (0, 0)\n",
      "UMPQ: UGC dataset shape: (30, 40)\n",
      "ZION: News dataset shape: (1, 2)\n",
      "ZION: UGC dataset shape: (31, 35)\n",
      "\n",
      "\n",
      "2020-10-23\n",
      "Found large change stocks: {'HSBC', 'AGIO', 'CCI', 'UMC', 'ALGN'}\n",
      "(5, 10)\n",
      "AGIO: News dataset shape: (0, 2)\n",
      "AGIO: UGC dataset shape: (30, 38)\n",
      "ALGN: News dataset shape: (0, 2)\n",
      "ALGN: UGC dataset shape: (30, 38)\n",
      "CCI: News dataset shape: (1, 2)\n",
      "CCI: UGC dataset shape: (30, 38)\n",
      "HSBC: News dataset shape: (0, 2)\n",
      "HSBC: UGC dataset shape: (31, 38)\n",
      "UMC: News dataset shape: (1, 2)\n",
      "UMC: UGC dataset shape: (33, 39)\n",
      "\n",
      "\n",
      "2020-10-26\n",
      "Found large change stocks: {'CAJ', 'DNKN'}\n",
      "(2, 10)\n",
      "CAJ: News dataset shape: (23, 2)\n",
      "CAJ: UGC dataset shape: (30, 36)\n",
      "DNKN: News dataset shape: (18, 2)\n",
      "DNKN: UGC dataset shape: (94, 41)\n",
      "\n",
      "\n",
      "2020-10-27\n",
      "Found large change stocks: {'HSBC', 'UMPQ', 'LLY', 'RARE', 'CAJ', 'CR', 'MT'}\n",
      "(7, 10)\n",
      "CAJ: News dataset shape: (64, 2)\n",
      "CAJ: UGC dataset shape: (31, 38)\n",
      "CR: News dataset shape: (24, 2)\n",
      "CR: UGC dataset shape: (30, 35)\n",
      "HSBC: News dataset shape: (4, 2)\n",
      "HSBC: UGC dataset shape: (37, 36)\n",
      "LLY: News dataset shape: (87, 2)\n",
      "LLY: UGC dataset shape: (80, 41)\n",
      "MT: News dataset shape: (1, 2)\n",
      "MT: UGC dataset shape: (30, 38)\n",
      "RARE: News dataset shape: (2, 2)\n",
      "RARE: UGC dataset shape: (31, 40)\n",
      "UMPQ: News dataset shape: (0, 0)\n",
      "UMPQ: UGC dataset shape: (30, 38)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "\n",
    "    Loading News and UGC data\n",
    "\n",
    "        stocks_key_words_dict\n",
    "        large_stock_df_dict\n",
    "    \n",
    "    Results: News and UGC\n",
    "        res_news_df_dict\n",
    "        res_ugc_df_dict\n",
    "\n",
    "    \n",
    "'''\n",
    "# stocks_key_words_dict\n",
    "stocks_key_words_dict = {}\n",
    "del_words = ['Ltd', 'Inc', 'Corp', 'Holdings', 'LLC', 'Corporation', 'PLC',\n",
    "             'HOLDERs', 'Co', 'Limited', 'Company',\n",
    "             'Providers', 'group', 'com', 'Brands']\n",
    "del_words = [w.lower() for w in del_words]\n",
    "\n",
    "w_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# large_stock_df_dict\n",
    "large_stock_df_dict = {}\n",
    "\n",
    "# results: News and UGC\n",
    "res_news_df_dict = {}\n",
    "res_ugc_df_dict = {}\n",
    "\n",
    "for day in dates_filename_list:\n",
    "    print(day)\n",
    "    \n",
    "    if unique_stocks_d[day] == set():\n",
    "        print('No large change stock found in day {}'.format(day))\n",
    "    else:\n",
    "        print('Found large change stocks:', unique_stocks_d[day])\n",
    "        \n",
    "        large_stock_df = get_large_stock_df(day, unique_stocks_d, first_large_change_d)\n",
    "        large_stock_df_dict[day] = large_stock_df\n",
    "\n",
    "        for s in sorted(list(unique_stocks_d[day])):\n",
    "            if s not in stocks_key_words_dict:\n",
    "                tmp_words = []\n",
    "                tmp_words.append(s.lower())\n",
    "\n",
    "                tmp_names = [w_lemmatizer.lemmatize(w.lower()) for w in re.findall(r'\\w+', large_stock_df[large_stock_df['Symbol'] == s]['Name'].values[0]) \\\n",
    "                             if w.lower() not in del_words]\n",
    "                tmp_words.append(' '.join(tmp_names))\n",
    "\n",
    "                tmp_words = list(set(tmp_words))\n",
    "                stocks_key_words_dict[s] = tmp_words\n",
    "\n",
    "        tmp_path = os.path.join(os.path.join(os.path.join(parent_dir, 'mid_large_cap_stocks'), \n",
    "                 day), 'threshold_{}/'.format(top_p[0]))\n",
    "\n",
    "        res_news_df_dict[day], \\\n",
    "        res_ugc_df_dict[day] = get_news_ugc_data(day, tmp_path, unique_stocks_d)\n",
    "\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from collections import Counter\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "del_words.extend(['$', '\\n', '\\n\\n', '|'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-02 HSBC\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['hsbc']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day = dates_filename_list[0]\n",
    "s = sorted(list(unique_stocks_d[day]))[0]\n",
    "print(day, s)\n",
    "\n",
    "stocks_key_words_dict[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Word frequency:\n",
    "        News\n",
    "    \n",
    "        UGC\n",
    "    \n",
    "'''\n",
    "# news\n",
    "tmp_news_title = res_news_df_dict[day][s]['title'].apply(lambda x: nlp(x))\n",
    "\n",
    "news_words = [token.text for sent in tmp_news_title for token in sent if not token.is_stop and not token.is_punct and not token.is_space]\n",
    "news_words = [w_lemmatizer.lemmatize(w.lower()) for w in news_words if w.lower() not in del_words]\n",
    "\n",
    "news_word_freq = Counter(news_words)\n",
    "\n",
    "# UGC\n",
    "tmp_ugc_data = res_ugc_df_dict[day][s]['body'].apply(lambda x: nlp(x))\n",
    "\n",
    "ugc_words = [token.text for sent in tmp_ugc_data for token in sent if not token.is_stop and not token.is_punct and not token.is_space]\n",
    "ugc_words = [w_lemmatizer.lemmatize(w.lower()) for w in ugc_words if w.lower() not in del_words]\n",
    "\n",
    "ugc_word_freq = Counter(ugc_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hsbc', 3),\n",
       " ('bank', 3),\n",
       " ('market', 2),\n",
       " ('nyse', 1),\n",
       " ('currently', 1),\n",
       " ('99.45', 1),\n",
       " ('52-week', 1),\n",
       " ('high', 1),\n",
       " ('upside', 1),\n",
       " ('potential', 1),\n",
       " ('surprise', 1),\n",
       " ('marketing', 1),\n",
       " ('sentinel', 1),\n",
       " ('oman', 1),\n",
       " ('card', 1),\n",
       " ('payment', 1),\n",
       " ('report-', 1),\n",
       " ('growth', 1),\n",
       " ('opportunity', 1),\n",
       " ('company', 1)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_word_freq.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hsbc', 37),\n",
       " ('pm', 11),\n",
       " ('adr', 7),\n",
       " ('short', 6),\n",
       " ('stock', 6),\n",
       " ('form', 4),\n",
       " ('6-k', 4),\n",
       " ('filed', 4),\n",
       " ('sentiment', 4),\n",
       " ('close', 3),\n",
       " ('li', 3),\n",
       " ('15', 3),\n",
       " ('jpm', 3),\n",
       " ('negative', 3),\n",
       " ('social', 3),\n",
       " ('medium', 3),\n",
       " ('https://socialsentiment.io/stocks/symbol/hsbc/', 3),\n",
       " ('week', 3),\n",
       " ('+', 3),\n",
       " ('soon', 2)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ugc_word_freq.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PoS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_words_noun_verb_adj = [(token.text, token.pos_) for sent in tmp_news_title for token in sent \\\n",
    " if not token.is_stop and not token.is_punct and not token.is_space \\\n",
    " and token.pos_ in ('VERB', 'NOUN', 'ADJ')]\n",
    "news_words_noun_verb_adj = [(w_lemmatizer.lemmatize(w.lower()), t) for w, t in news_words_noun_verb_adj \\\n",
    "                           if w.lower() not in del_words]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('high', 'ADJ'), 1),\n",
       " (('surprise', 'VERB'), 1),\n",
       " (('marketing', 'NOUN'), 1),\n",
       " (('sentinel', 'NOUN'), 1),\n",
       " (('market', 'NOUN'), 1)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(news_words_noun_verb_adj).most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
